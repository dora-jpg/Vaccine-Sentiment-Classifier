{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dora-jpg/Vaccine-Sentiment-Classifier/blob/main/AI2_HM3_bidirectional_RNN_with_LSTM_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLAaIaAE9z4D"
      },
      "source": [
        "# Artificial Intelligence II - Homework 3\n",
        "# ðŸ’‰Vaccine sentiment classifier using bidirectional Recursive Neural Networks with LSTM/GRU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykBHfl_LJL-p"
      },
      "source": [
        "In this exercise we are going to develop a vaccine sentiment classifier that classifies tweets in pro-vax, anti-vax and neutral classes using bidirectional Recursive Neural Networks. I experimented with LSTM and GRU.\n",
        "For data preprocessing and feature extracting I experimented with a GloVe pretrained model. I used a simple preprocessing funtion that removes puctuation, html tags and urls. I kept emojis because I noticed that some of them are included in the pretrained glove model. I used the glove.twitter.27B.200d (in Homework 2 I used the glove.twitter.27B.50d). For exercise 2 I added an attention parameter to all implemented models that can be set True to activate it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLs58fONFrG3"
      },
      "source": [
        "**Note:** \n",
        "I seeded numpy.random and torch.random in the cells that define each model so that I get the same results in every run and can compare scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i0cE5-17AUF",
        "outputId": "ed312425-af14-4573-c121-57556fc53614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g50JWXbB2ze"
      },
      "source": [
        "# Import Libraries and Read Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries that will be used in this notebook, define a seeding function and set device to cuda if available.\n"
      ],
      "metadata": {
        "id": "rIUe14-z7O9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7j9F1YTMFuE",
        "outputId": "0dd0edf4-1bff-4ebb-b2c7-0e41f1a875ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchtext) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Working on: cuda\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Evaluation metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn.metrics\n",
        "import seaborn as sns\n",
        "import random\n",
        "import sys\n",
        "from IPython.display import Image\n",
        "\n",
        "# for text preprocessing\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize\n",
        "\n",
        "# Batches\n",
        "!pip install torchtext\n",
        "from torchtext import vocab\n",
        "from torchtext.legacy.data import Field,Dataset,LabelField,BucketIterator\n",
        "from torchtext.legacy.data import Dataset, Example\n",
        "\n",
        "# Learning curves\n",
        "from itertools import cycle\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Confusion Matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "def set_seed(seed = 1234):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    !CUBLAS_WORKSPACE_CONFIG=:4096:2 # for cuda deterministic behavior\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.enabled = False\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # torch.use_deterministic_algorithms(False)\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    \n",
        "set_seed()\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Working on:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3T_ITrECxKu"
      },
      "source": [
        "Read train and validation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DCe_10itB0Pu"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Artificial Intelligence II/vaccine_train_set.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Artificial Intelligence II/vaccine_validation_set.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA3NQAAuKwjf"
      },
      "source": [
        " We don't need the first column of the datasets because it is an index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qA3P1gymKEwR"
      },
      "outputs": [],
      "source": [
        "# get rid of first column\n",
        "df_train = df_train.iloc[: , 1:]\n",
        "df_test = df_test.iloc[: , 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "awuvFK_yCuAO",
        "outputId": "d03d4dc0-8491-463c-89a4-93ff265f174a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4fff429f-d123-4ced-a546-cc96813c49d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sip N Shop Come thru right now #Marjais #Popul...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I don't know about you but My family and I wil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@MSignorile Immunizations should be mandatory....</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>President Obama spoke in favor of vaccination ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"@myfoxla: Arizona monitoring hundreds for mea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fff429f-d123-4ced-a546-cc96813c49d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fff429f-d123-4ced-a546-cc96813c49d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fff429f-d123-4ced-a546-cc96813c49d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet  label\n",
              "0  Sip N Shop Come thru right now #Marjais #Popul...      0\n",
              "1  I don't know about you but My family and I wil...      1\n",
              "2  @MSignorile Immunizations should be mandatory....      2\n",
              "3  President Obama spoke in favor of vaccination ...      0\n",
              "4  \"@myfoxla: Arizona monitoring hundreds for mea...      0"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1SCqSG05CMpd",
        "outputId": "3232d4ff-a175-4ced-bbfc-fa9cf8080e25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-448b8cfb-5eb1-4b09-b423-0de2b8b02247\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user They had a massive surge in with covid d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Required vaccines for school: Parents and guar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>â€œ@KCStar: Two more Johnson County children hav...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NV can do better. Which states are the best (a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nothing like killing ourselves w/ our own fear...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-448b8cfb-5eb1-4b09-b423-0de2b8b02247')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-448b8cfb-5eb1-4b09-b423-0de2b8b02247 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-448b8cfb-5eb1-4b09-b423-0de2b8b02247');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               tweet  label\n",
              "0  @user They had a massive surge in with covid d...      1\n",
              "1  Required vaccines for school: Parents and guar...      0\n",
              "2  â€œ@KCStar: Two more Johnson County children hav...      0\n",
              "3  NV can do better. Which states are the best (a...      2\n",
              "4  Nothing like killing ourselves w/ our own fear...      2"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(df_test.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22fsx7JjEMfF"
      },
      "source": [
        "# Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qCtGlrAOjpT"
      },
      "source": [
        "## Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning involves convertion to lowercase, removal of urls, html tags, punctuation and stopwords. As a explained in the introduction, I decided to keep the emojis as they can show sentiment. "
      ],
      "metadata": {
        "id": "dt1FRrIF7voS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bW2gJG0SlR81"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "\n",
        "def tweets_cleaning(x, remove_emojis=False, remove_stop_words=True):\n",
        "    \"\"\"Apply function to a clean a tweet\"\"\"\n",
        "    x = x.lower().strip()\n",
        "    # romove urls\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    x = url.sub(r'',x)\n",
        "    # remove html tags\n",
        "    html = re.compile(r'<.*?>')\n",
        "    x = html.sub(r'',x)\n",
        "    # remove punctuation\n",
        "    operator = str.maketrans(' ',' ',string.punctuation)\n",
        "    x = x.translate(operator)\n",
        "    if remove_emojis:\n",
        "        x = x.encode('ascii', 'ignore').decode('utf8').strip()\n",
        "    if remove_stop_words:\n",
        "        x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7r9stfORI5rQ"
      },
      "outputs": [],
      "source": [
        "## APPLY the cleaning function to the text column\n",
        "df_train['clean_tweet'] = df_train['tweet'].apply(tweets_cleaning)\n",
        "df_test['clean_tweet'] = df_test['tweet'].apply(tweets_cleaning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PRjL4WS3E4Jc"
      },
      "outputs": [],
      "source": [
        "Y_train = df_train['label'] #Only keep value\n",
        "Y_test = df_test['label'] #Only keep value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb_35RgUQJFf",
        "outputId": "c23f4e77-0540-41cf-80e0-4a62d9de582f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        sip n shop come thru right marjais popularnobo...\n",
              "1        dont know family take covid19 vaccine anytime ...\n",
              "2        msignorile immunizations mandatory period okla...\n",
              "3        president obama spoke favor vaccination childr...\n",
              "4        myfoxla arizona monitoring hundreds measles li...\n",
              "                               ...                        \n",
              "15971    salon u believe antivax nutcases caused measle...\n",
              "15972    feel parents dont vaccinate kids\\r\\n\\r\\nmeasle...\n",
              "15973          70 preschoolers tested measles simi valley \n",
              "15974    finance minister budget offers room procure co...\n",
              "15975    date vaccines take cdcâ€™s vaccine quiz find vac...\n",
              "Name: clean_tweet, Length: 15976, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df_train['clean_tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgKREelmQM3f",
        "outputId": "459a1d2c-7b66-43ff-e86b-84c4e817e60b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        sip n shop come thru right marjais popularnobo...\n",
              "1        dont know family take covid19 vaccine anytime ...\n",
              "2        msignorile immunizations mandatory period okla...\n",
              "3        president obama spoke favor vaccination childr...\n",
              "4        myfoxla arizona monitoring hundreds measles li...\n",
              "                               ...                        \n",
              "15971    salon u believe antivax nutcases caused measle...\n",
              "15972    feel parents dont vaccinate kids\\r\\n\\r\\nmeasle...\n",
              "15973          70 preschoolers tested measles simi valley \n",
              "15974    finance minister budget offers room procure co...\n",
              "15975    date vaccines take cdcâ€™s vaccine quiz find vac...\n",
              "Name: clean_tweet, Length: 15976, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_train['clean_tweet']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMXtkwBrJtSi"
      },
      "source": [
        "Overview of label distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxpyM6vOHrRv",
        "outputId": "a50df739-76eb-4d90-e235-0199045ac92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data\n",
            "label 0: 7458\n",
            "label 1: 2073\n",
            "label 2: 6445\n",
            "validation data\n",
            "label 0: 1065\n",
            "label 1: 296\n",
            "label 2: 921\n"
          ]
        }
      ],
      "source": [
        "print(\"train data\")\n",
        "print(\"label 0:\",Y_train[Y_train== 0].count())\n",
        "print(\"label 1:\",Y_train[Y_train== 1].count())\n",
        "print(\"label 2:\",Y_train[Y_train== 2].count())\n",
        "print(\"validation data\")\n",
        "print(\"label 0:\",Y_test[Y_test== 0].count())\n",
        "print(\"label 1:\",Y_test[Y_test== 1].count())\n",
        "print(\"label 2:\",Y_test[Y_test== 2].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "RKmLcKZYL34v",
        "outputId": "0e585586-73b0-4e32-8ee2-b9d6d26fac2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "labels = ['0', '1', '2']\n",
        "train = [Y_train[Y_train== 0].count(),Y_train[Y_train== 1].count(),Y_train[Y_train== 2].count()]\n",
        "test= [Y_test[Y_test== 0].count(),Y_test[Y_test== 1].count(),Y_test[Y_test== 2].count()]\n",
        "ax.bar(labels, train)\n",
        "ax.bar(labels, test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Z0u5rJ0ToQ"
      },
      "source": [
        "Label 1 has very few instances so we expect that it has a lower score than the other 2 labels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Bc0vQAEvnD"
      },
      "source": [
        "# Features Extraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKJyG0WzOUyb"
      },
      "source": [
        "## GloVe representation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Approach: Create fixed size vectors for glove"
      ],
      "metadata": {
        "id": "Lmju4O8y8yp4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QS4tdTpGpkF"
      },
      "source": [
        "Load pre-trained GloVe vectors into a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Wc0NC0cvGov-"
      },
      "outputs": [],
      "source": [
        "embeddings_dict = {}\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Artificial Intelligence II/glove.twitter.27B.200d.txt.gz (Unzipped Files)/glove.twitter.27B.200d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    embeddings_dict[word]=vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4lM2nRpj6ns"
      },
      "source": [
        "Find the vector for each word in each tweet. If the tweet has more words than the number specified by `padding` then cut the tweet there. If it has less words than `padding` number then add vectors with zeros. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWzahQgiaoQB",
        "outputId": "5a4d2a81-b3ef-4d76-e68e-2ba72af74822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [[-0.16063, -0.28647, -0.60789, 0.42767, -0.11...\n",
              "1        [[-0.33784, 0.54451, -0.1921, 0.43394, -0.4804...\n",
              "2        [[-0.33915, -0.28546, -0.26841, 0.014209, 0.23...\n",
              "3        [[0.34601, 0.30425, -0.098192, 0.08868, -0.359...\n",
              "4        [[0.2101, -0.21056, -0.36659, -0.37312, 0.0773...\n",
              "                               ...                        \n",
              "15971    [[0.15358, -0.30126, -0.3615, 0.24909, 0.72131...\n",
              "15972    [[0.061424, 0.42365, -0.13984, 0.26585, -0.215...\n",
              "15973    [[0.058755, 0.018929, 0.24508, 0.021967, -0.23...\n",
              "15974    [[0.14571, -0.31397, -0.39098, -0.16087, -0.02...\n",
              "15975    [[-0.48751, 0.11036, 0.16039, -0.15214, -0.217...\n",
              "Name: features, Length: 15976, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def find_glove(text, padding=31):\n",
        "  tokens = word_tokenize(text.lower())\n",
        "  res = [ embeddings_dict[token] for token in tokens if (token in embeddings_dict) ]\n",
        "  res = res[:padding]\n",
        "  if len(res)<padding:\n",
        "    for i in range(padding-len(res)):\n",
        "      res.append(np.zeros(200))\n",
        "  return res\n",
        "\n",
        "df_train['features'] = df_train['clean_tweet'].apply(find_glove)\n",
        "df_test['features'] = df_test['clean_tweet'].apply(find_glove)\n",
        "df_train['features']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY44VnKTKVgc"
      },
      "source": [
        "# Bidirectional RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8cckzgBBcMR"
      },
      "source": [
        "## Fixed length of the sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A model that takes fixed size vectors as input."
      ],
      "metadata": {
        "id": "QPH5tRiCFO-a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ukzh_Wpm0Zrz"
      },
      "outputs": [],
      "source": [
        "class BRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, cell, dropout=0.3, attention=True):\n",
        "        super(BRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell = cell\n",
        "        self.bidirectional = True\n",
        "        self.attention = attention\n",
        "        self.scale = 1. / math.sqrt(hidden_size)\n",
        "        if (cell == 'LSTM'):\n",
        "          self.rnn = nn.LSTM(\n",
        "              input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout\n",
        "          )\n",
        "        else:\n",
        "          self.rnn = nn.GRU(\n",
        "              input_size, hidden_size, num_layers, batch_first=True, bidirectional=True, dropout=dropout\n",
        "          )\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if (self.cell == 'LSTM'):\n",
        "          out, hidden = self.rnn(x)\n",
        "          hidden = hidden[1]\n",
        "        else:\n",
        "          out, hidden = self.rnn(x)\n",
        "\n",
        "        if (self.attention==True):\n",
        "            # print(\"hi\")\n",
        "            if (self.bidirectional==True):\n",
        "                hidden = torch.cat([hidden[-1], hidden[-2]], dim=1) # concatinate the last 2 hidden cells (backward & forward)\n",
        "            else:\n",
        "                hidden = hidden[-1]\n",
        "\n",
        "            query = hidden.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
        "            values = out\n",
        "            # print(\"query\", query.shape)\n",
        "            # print(\"keys\", keys.shape)\n",
        "            # keys = out.transpose(1,2) # [BxTxK] -> [BxKxT]\n",
        "            # print(\"keys\", keys.shape)\n",
        "            attention_scores = torch.bmm(query, out.transpose(1,2)) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
        "            attention_distribution = F.softmax(attention_scores.mul_(self.scale), dim=2) # scale, normalize\n",
        "\n",
        "            # out = out # [TxBxV] -> [BxTxV]\n",
        "            # print(\"values\", values.shape)\n",
        "            out = torch.bmm(attention_distribution, out).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
        "\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For skip connections, I had to re-define the model to keep the output of each layer of the stacked rnn."
      ],
      "metadata": {
        "id": "XSBFv7TmikYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class skipBRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, cell, dropout=0.3, attention=True):\n",
        "        super(skipBRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell = cell\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.attention = attention\n",
        "        self.bidirectional = True\n",
        "        self.scale = 1. / math.sqrt(hidden_size)\n",
        "        \n",
        "        if (cell == 'LSTM'):\n",
        "            rnn = nn.LSTM\n",
        "        else:\n",
        "            rnn = nn.GRU\n",
        "\n",
        "        self.rnns = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            input_size = input_size if i == 0 else hidden_size*2\n",
        "            self.rnns.append(rnn(input_size, hidden_size, 1, batch_first=True, bidirectional=True))\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        sent_variable = x\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            if i != 0:\n",
        "                sent_variable = self.dropout(sent_variable.detach())\n",
        "\n",
        "            out, hidden = self.rnns[i](sent_variable.detach())\n",
        "            hidden = hidden[1]\n",
        "\n",
        "            if i == 0:\n",
        "                sent_variable = out.detach()\n",
        "\n",
        "            sent_variable = torch.cat((sent_variable,out.detach()),dim=1)\n",
        "\n",
        "        if (self.attention==True):\n",
        "            # print(\"hi\")\n",
        "            if (self.bidirectional==True):\n",
        "                hidden = torch.cat([hidden[-1], hidden[-2]], dim=1) # concatinate the last 2 hidden cells (backward & forward)\n",
        "            else:\n",
        "                hidden = hidden[-1]\n",
        "\n",
        "            query = hidden.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
        "            values = out\n",
        "\n",
        "            attention_scores = torch.bmm(query, out.transpose(1,2)) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
        "            attention_distribution = F.softmax(attention_scores.mul_(self.scale), dim=2) # scale, normalize\n",
        "\n",
        "            out = torch.bmm(attention_distribution, out).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
        "\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "qG8rdr9SG9Zg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create tensors and a train dataset to pass to dataloader.\n"
      ],
      "metadata": {
        "id": "E5b6HsR3Efqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(np.stack(df_train['features'], axis=0), dtype=torch.float)\n",
        "y = torch.tensor(np.stack(df_train['label'], axis=0), dtype=torch.long)\n",
        "\n",
        "print(f\"x shape: {x.shape}\")\n",
        "print(f\"y shape: {y.shape}\")\n",
        "\n",
        "dataset = torch.utils.data.TensorDataset(x, y)\n",
        "\n",
        "x_test = torch.tensor(np.stack(df_test['features'], axis=0), dtype=torch.float)\n",
        "y_test = torch.tensor(np.stack(df_test['label'], axis=0), dtype=torch.long)\n",
        "\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1WcQYtxMAgT",
        "outputId": "fa0c3c42-5616-4d17-d21e-de0d5d65b550"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: torch.Size([15976, 31, 200])\n",
            "y shape: torch.Size([15976])\n",
            "x_test shape: torch.Size([2282, 31, 200])\n",
            "y_test shape: torch.Size([2282])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluation function"
      ],
      "metadata": {
        "id": "TCzldPsPEmMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "ZN3Vfva8Ou7o"
      },
      "outputs": [],
      "source": [
        "def train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device):\n",
        "    x_test = x_test.to(device=device).squeeze(1)\n",
        "    y_test = y_test.to(device=device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    epoch_loss = []\n",
        "    validation_loss = []\n",
        "    f1 = []\n",
        "\n",
        "    # Train Network\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_losses = []\n",
        "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "            # Get data to cuda if possible\n",
        "            data = data.to(device=device).squeeze(1)\n",
        "            targets = targets.to(device=device)\n",
        "\n",
        "            # forward\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            # backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip params\n",
        "            for param in model.parameters():\n",
        "                if param.grad is None:\n",
        "                    continue\n",
        "                grad_val = torch.clamp(param.grad, -5, 5)\n",
        "\n",
        "            # gradient descent or adam step\n",
        "            optimizer.step()\n",
        "            \n",
        "        epoch_loss.append(sum(batch_losses)/len(train_loader))\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_test_pred = model(x_test)\n",
        "\n",
        "        val_loss = criterion(y_test_pred, y_test)\n",
        "\n",
        "        validation_loss.append(val_loss.item())\n",
        "        f1score = f1_score(y_test.cpu(), y_test_pred.max(1)[1].cpu(), average='micro')\n",
        "        f1.append(f1score)\n",
        "        print(f\"Epoch {epoch:3}: Training Loss = {sum(batch_losses)/len(train_loader):.5f}  Validation Loss = {validation_loss[epoch]:.5f} f1= {f1score:.5f}\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        scores = model(x_test)\n",
        "        _, y_pred = scores.max(1)\n",
        "\n",
        "    if device==torch.device(\"cuda\"):\n",
        "        y_pred = y_pred.cpu()\n",
        "    \n",
        "    print(\"\")\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(Y_test, y_pred)\n",
        "    print(f\"         precision\\t  recall\\t   f1\\t    \\tsupport\")\n",
        "    print(f\"---------------------------------------------------------------\")\n",
        "    print(f\"label 0 | {precision[0]*100:0.4f}\\t {recall[0]*100:0.4f}\\t {f1[0]*100:0.4f}\\t {support[0]}\")\n",
        "    print(f\"label 1 | {precision[1]*100:.4f}\\t {recall[1]*100:.4f}\\t {f1[1]*100:2.4f}\\t {support[1]}\")\n",
        "    print(f\"label 2 | {precision[2]*100:0.4f}\\t {recall[2]*100:0.4f}\\t {f1[2]*100:0.4f}\\t {support[2]}\")\n",
        "\n",
        "    average = precision_recall_fscore_support(Y_test, y_pred, average='micro')\n",
        "    print(f\"micro   | {average[0]*100:0.4f}\\t {average[1]*100:0.4f}\\t {average[2]*100:0.4f}\\t -\")\n",
        "\n",
        "    return epoch_loss, validation_loss, y_pred, scores, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentation\n",
        "\n"
      ],
      "metadata": {
        "id": "_dXVej-uEq6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 2\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI4xnAymwg58",
        "outputId": "4e9d39ea-b12d-49c7-b8b9-d6048a0fd20b"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.76256  Validation Loss = 0.68623 f1= 0.70377\n",
            "Epoch   1: Training Loss = 0.64724  Validation Loss = 0.66522 f1= 0.70684\n",
            "Epoch   2: Training Loss = 0.57245  Validation Loss = 0.67380 f1= 0.71472\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 82.1772\t 72.3005\t 76.9231\t 1065\n",
            "label 1 | 54.1502\t 46.2838\t 49.9089\t 296\n",
            "label 2 | 66.3004\t 78.6102\t 71.9324\t 921\n",
            "micro   | 71.4724\t 71.4724\t 71.4724\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding 1 layer. We observe better result."
      ],
      "metadata": {
        "id": "mVonPy5p5izj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIWDTijQ5d51",
        "outputId": "6cca66ab-6159-4644-ff13-0cfc2f9ca8c6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.79116  Validation Loss = 0.71961 f1= 0.68230\n",
            "Epoch   1: Training Loss = 0.66653  Validation Loss = 0.68966 f1= 0.70421\n",
            "Epoch   2: Training Loss = 0.60277  Validation Loss = 0.66701 f1= 0.71911\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.1735\t 80.3756\t 79.2593\t 1065\n",
            "label 1 | 52.8384\t 40.8784\t 46.0952\t 296\n",
            "label 2 | 69.3111\t 72.0955\t 70.6759\t 921\n",
            "micro   | 71.9106\t 71.9106\t 71.9106\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add a layer and 2 epochs. We see that the 2 more epochs overfit because the validation loss and f1 score get worse."
      ],
      "metadata": {
        "id": "u8jM7whU5-tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4NXXn85y38",
        "outputId": "87ce742d-fe10-4de2-b83f-6076795bde62"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.79116  Validation Loss = 0.71961 f1= 0.68230\n",
            "Epoch   1: Training Loss = 0.66653  Validation Loss = 0.68966 f1= 0.70421\n",
            "Epoch   2: Training Loss = 0.60277  Validation Loss = 0.66701 f1= 0.71911\n",
            "Epoch   3: Training Loss = 0.53511  Validation Loss = 0.72830 f1= 0.70508\n",
            "Epoch   4: Training Loss = 0.48418  Validation Loss = 0.69365 f1= 0.70771\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 81.1975\t 72.5822\t 76.6485\t 1065\n",
            "label 1 | 64.3357\t 31.0811\t 41.9134\t 296\n",
            "label 2 | 63.1845\t 81.4332\t 71.1575\t 921\n",
            "micro   | 70.7713\t 70.7713\t 70.7713\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 64\n",
        "num_classes = 3\n",
        "batch_size = 64\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 7\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uXduJJg95wF",
        "outputId": "02444a74-7c68-4c02-f25f-8bd71d8cbf07"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.78193  Validation Loss = 0.69781 f1= 0.69588\n",
            "Epoch   1: Training Loss = 0.67241  Validation Loss = 0.66963 f1= 0.71604\n",
            "Epoch   2: Training Loss = 0.60178  Validation Loss = 0.68732 f1= 0.71341\n",
            "Epoch   3: Training Loss = 0.53395  Validation Loss = 0.71796 f1= 0.70727\n",
            "Epoch   4: Training Loss = 0.47705  Validation Loss = 0.75833 f1= 0.70508\n",
            "Epoch   5: Training Loss = 0.42783  Validation Loss = 0.76688 f1= 0.70158\n",
            "Epoch   6: Training Loss = 0.37917  Validation Loss = 0.79579 f1= 0.70070\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.0488\t 75.1174\t 76.5550\t 1065\n",
            "label 1 | 47.6048\t 53.7162\t 50.4762\t 296\n",
            "label 2 | 69.3391\t 69.4897\t 69.4143\t 921\n",
            "micro   | 70.0701\t 70.0701\t 70.0701\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Best\" parameters but with skip connections. I will make the network larger as skip connections are better for large networks and to train a larger network we need more epochs."
      ],
      "metadata": {
        "id": "BHqFhbcrAc75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 5\n",
        "hidden_size = 64\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 7\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = skipBRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFj-IDBiAcRh",
        "outputId": "5f649342-7452-4df4-f1cb-b20e3eb6f885"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.91019  Validation Loss = 0.82296 f1= 0.63059\n",
            "Epoch   1: Training Loss = 0.82625  Validation Loss = 0.77451 f1= 0.64549\n",
            "Epoch   2: Training Loss = 0.80460  Validation Loss = 0.75565 f1= 0.66170\n",
            "Epoch   3: Training Loss = 0.77872  Validation Loss = 0.74421 f1= 0.66214\n",
            "Epoch   4: Training Loss = 0.77041  Validation Loss = 0.72384 f1= 0.67485\n",
            "Epoch   5: Training Loss = 0.75888  Validation Loss = 0.73678 f1= 0.65294\n",
            "Epoch   6: Training Loss = 0.75080  Validation Loss = 0.72357 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.7669\t 74.5540\t 76.1266\t 1065\n",
            "label 1 | 47.6744\t 27.7027\t 35.0427\t 296\n",
            "label 2 | 62.0753\t 73.3985\t 67.2637\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Best\" parameters but without attention.\n",
        "\n",
        "We observe that it doesn't learn label 1 at all. The improvement in the version with attention is significant."
      ],
      "metadata": {
        "id": "w2rHsah5ApzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=False).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVAlbRbbApzJ",
        "outputId": "d9e43cc4-285a-4818-f3e3-ca277eb03b7c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.88929  Validation Loss = 0.78293 f1= 0.65513\n",
            "Epoch   1: Training Loss = 0.77012  Validation Loss = 0.76495 f1= 0.66696\n",
            "Epoch   2: Training Loss = 0.73001  Validation Loss = 0.74068 f1= 0.68273\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 81.4050\t 73.9906\t 77.5209\t 1065\n",
            "label 1 | 0.0000\t 0.0000\t 0.0000\t 296\n",
            "label 2 | 58.5997\t 83.6048\t 68.9038\t 921\n",
            "micro   | 68.2734\t 68.2734\t 68.2734\t -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try 2 layers and a larger hidden_size."
      ],
      "metadata": {
        "id": "XjjH3Il5EGSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 2\n",
        "hidden_size = 128\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=False).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KftCyNqjESBT",
        "outputId": "019977c5-bf22-4505-ee6b-1fe1c2961213"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.98590  Validation Loss = 0.94963 f1= 0.54207\n",
            "Epoch   1: Training Loss = 0.82077  Validation Loss = 0.74600 f1= 0.66608\n",
            "Epoch   2: Training Loss = 0.71422  Validation Loss = 0.70798 f1= 0.68405\n",
            "Epoch   3: Training Loss = 0.65371  Validation Loss = 0.72892 f1= 0.68011\n",
            "Epoch   4: Training Loss = 0.60167  Validation Loss = 0.69840 f1= 0.70026\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.6423\t 78.8732\t 77.7418\t 1065\n",
            "label 1 | 50.6608\t 38.8514\t 43.9771\t 296\n",
            "label 2 | 67.0490\t 69.8154\t 68.4043\t 921\n",
            "micro   | 70.0263\t 70.0263\t 70.0263\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try 2 layers and a larger hidden_size."
      ],
      "metadata": {
        "id": "9J74oFbbGFw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 2\n",
        "hidden_size = 256\n",
        "num_classes = 3\n",
        "batch_size = 256\n",
        "cell = 'LSTM'\n",
        "dropout = 0.2\n",
        "\n",
        "epochs = 8\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=False).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c62d5e37-52cd-4c0b-d7ab-196523e9a1c4",
        "id": "upzr9r_1GFw6"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.96748  Validation Loss = 0.80191 f1= 0.65118\n",
            "Epoch   1: Training Loss = 0.77014  Validation Loss = 0.75083 f1= 0.67134\n",
            "Epoch   2: Training Loss = 0.72127  Validation Loss = 0.71768 f1= 0.67572\n",
            "Epoch   3: Training Loss = 0.64952  Validation Loss = 0.70514 f1= 0.68843\n",
            "Epoch   4: Training Loss = 0.57107  Validation Loss = 0.71652 f1= 0.69457\n",
            "Epoch   5: Training Loss = 0.49438  Validation Loss = 0.76070 f1= 0.69369\n",
            "Epoch   6: Training Loss = 0.41721  Validation Loss = 0.81722 f1= 0.68317\n",
            "Epoch   7: Training Loss = 0.34523  Validation Loss = 0.84297 f1= 0.69632\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.5027\t 77.3709\t 75.9097\t 1065\n",
            "label 1 | 57.6923\t 40.5405\t 47.6190\t 296\n",
            "label 2 | 66.6322\t 70.0326\t 68.2901\t 921\n",
            "micro   | 69.6319\t 69.6319\t 69.6319\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=False).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "id": "BMXJdj8eEEfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Best\" parameters but with skip connections and without attention."
      ],
      "metadata": {
        "id": "au50t4WDAyfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'LSTM'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = skipBRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=False).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "id": "_j9fvq7IAyfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trying GRU."
      ],
      "metadata": {
        "id": "_CjX5_FUC7jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed() # for model and dataloader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 3\n",
        "hidden_size = 32\n",
        "num_classes = 3\n",
        "batch_size = 128\n",
        "cell = 'GRU'\n",
        "dropout = 0.3\n",
        "\n",
        "epochs = 3\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Initialize network\n",
        "model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=True).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores, f1 = train(model, learning_rate, dataset, batch_size, epochs, x_test, y_test, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "x-xHJaTZC6wd",
        "outputId": "f91e8c38-eb81-4c40-92d0-3f1a23a34fff"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.76926  Validation Loss = 0.75763 f1= 0.64987\n",
            "Epoch   1: Training Loss = 0.66705  Validation Loss = 0.67199 f1= 0.70727\n",
            "Epoch   2: Training Loss = 0.59856  Validation Loss = 0.70829 f1= 0.70289\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.0579\t 83.0047\t 77.7143\t 1065\n",
            "label 1 | 57.7778\t 35.1351\t 43.6975\t 296\n",
            "label 2 | 69.0583\t 66.8838\t 67.9537\t 921\n",
            "micro   | 70.2892\t 70.2892\t 70.2892\t -\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-4c19d34e3306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_grid_search(net, max_epochs = 8):\n",
        "    dict_best = {}\n",
        "    best_loss = 1.0\n",
        "    best_f1 = 0\n",
        "    dict_best_f1 = {}\n",
        "    curr = {}\n",
        "\n",
        "    for num_layers in [2,3,4]:\n",
        "        curr['num_layers'] = num_layers\n",
        "        for hidden_size in [32, 64, 128]:\n",
        "            curr['hidden_size'] = hidden_size\n",
        "            for batch_size in [64, 128]:\n",
        "                curr['batch_size'] = batch_size\n",
        "                for dropout in [0.0,0.1,0.2,0.3]:\n",
        "                    curr['dropout'] = dropout\n",
        "                    for attention in [False, True]:\n",
        "                        curr['attention'] = attention\n",
        "                        print(f\"num_layers: {curr['num_layers']},hidden_size: {curr['hidden_size']}, batch_size: {curr['batch_size']}, dropout: {curr['dropout']}, attention: {curr['attention']}\")\n",
        "                        set_seed() # for model and dataloader\n",
        "                        model = BRNN(input_size, hidden_size, num_layers, num_classes, cell, dropout=dropout, attention=attention).to(device)\n",
        "                        _, validation_loss, _, _, f1score = train(model, learning_rate, dataset, batch_size, max_epochs, x_test, y_test, device)\n",
        "                        indexloss = np.array(validation_loss).argmin()\n",
        "                        indexf1 = np.array(f1score).argmin()\n",
        "                        curr['epoch_f1'] = indexf1+1\n",
        "                        curr['epoch_loss'] = indexloss+1\n",
        "                        if (validation_loss[indexloss] < best_loss):\n",
        "                            best_loss = validation_loss[indexloss]\n",
        "                            dict_best = curr\n",
        "                        print(f1score)\n",
        "                        if (f1score[indexf1] > best_f1):\n",
        "                            best_f1 = f1score[indexf1]\n",
        "                            dict_best_f1 = curr\n",
        "    # curr['num_layers'] = 1\n",
        "    # curr['dropout'] = 0.0\n",
        "    # for hidden_size in [32, 64, 128]:\n",
        "    #     curr['hidden_size'] = hidden_size\n",
        "    #     for batch_size in [64, 128]:\n",
        "    #         curr['batch_size'] = batch_size\n",
        "    #         for attention in [False, True]:\n",
        "    #             curr['attention'] = attention\n",
        "    #             print(f\"num_layers: {curr['num_layers']},hidden_size: {curr['hidden_size']}, batch_size: {curr['batch_size']}, dropout: {curr['dropout']}, attention: {curr['attention']}\")\n",
        "    #             set_seed() # for model and dataloader\n",
        "    #             model = BRNN(input_size, hidden_size, 1, num_classes, cell, dropout=0.0, attention=True).to(device)\n",
        "    #             _, validation_loss, _, _, f1 = train(model, learning_rate, dataset, batch_size, max_epochs, x_test, y_test, device)\n",
        "    #             index = np.array(validation_loss).argmin()\n",
        "    #             if (validation_loss[index] < best_loss):\n",
        "    #                 best_loss = validation_loss[index]\n",
        "    #                 dict_best = curr\n",
        "    \n",
        "    return dict_best, best_loss, dict_best_f1, best_f1"
      ],
      "metadata": {
        "id": "R2G8k_eGG9Vf"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_best, best_loss, dict_best_f1, best_f1 = custom_grid_search(BRNN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej3ARRw8Lv7X",
        "outputId": "3e6caffc-4f7e-4a10-8489-52bc566f2e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.81739  Validation Loss = 0.73163 f1= 0.67835\n",
            "Epoch   1: Training Loss = 0.68705  Validation Loss = 0.70272 f1= 0.69544\n",
            "Epoch   2: Training Loss = 0.62746  Validation Loss = 0.70856 f1= 0.69018\n",
            "Epoch   3: Training Loss = 0.57834  Validation Loss = 0.72147 f1= 0.69106\n",
            "Epoch   4: Training Loss = 0.52730  Validation Loss = 0.73543 f1= 0.69720\n",
            "Epoch   5: Training Loss = 0.49105  Validation Loss = 0.75294 f1= 0.69150\n",
            "Epoch   6: Training Loss = 0.45348  Validation Loss = 0.80627 f1= 0.68361\n",
            "Epoch   7: Training Loss = 0.42916  Validation Loss = 0.83916 f1= 0.67660\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.1855\t 72.0188\t 74.9756\t 1065\n",
            "label 1 | 42.6573\t 41.2162\t 41.9244\t 296\n",
            "label 2 | 64.5320\t 71.1183\t 67.6653\t 921\n",
            "micro   | 67.6599\t 67.6599\t 67.6599\t -\n",
            "[0.74975562 0.41924399 0.67665289]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.73762  Validation Loss = 0.68150 f1= 0.71209\n",
            "Epoch   1: Training Loss = 0.63416  Validation Loss = 0.66208 f1= 0.70815\n",
            "Epoch   2: Training Loss = 0.56148  Validation Loss = 0.73062 f1= 0.70070\n",
            "Epoch   3: Training Loss = 0.49079  Validation Loss = 0.75008 f1= 0.70114\n",
            "Epoch   4: Training Loss = 0.43330  Validation Loss = 0.75352 f1= 0.69632\n",
            "Epoch   5: Training Loss = 0.38309  Validation Loss = 0.84962 f1= 0.68668\n",
            "Epoch   6: Training Loss = 0.35035  Validation Loss = 0.85391 f1= 0.68799\n",
            "Epoch   7: Training Loss = 0.32476  Validation Loss = 0.94033 f1= 0.68142\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.3802\t 74.4601\t 74.9173\t 1065\n",
            "label 1 | 50.5495\t 46.6216\t 48.5062\t 296\n",
            "label 2 | 65.2038\t 67.7524\t 66.4537\t 921\n",
            "micro   | 68.1420\t 68.1420\t 68.1420\t -\n",
            "[0.74917336 0.48506151 0.66453674]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.82462  Validation Loss = 0.70869 f1= 0.68186\n",
            "Epoch   1: Training Loss = 0.68790  Validation Loss = 0.68316 f1= 0.69895\n",
            "Epoch   2: Training Loss = 0.62170  Validation Loss = 0.67772 f1= 0.71034\n",
            "Epoch   3: Training Loss = 0.56686  Validation Loss = 0.71571 f1= 0.70158\n",
            "Epoch   4: Training Loss = 0.52260  Validation Loss = 0.73026 f1= 0.69807\n",
            "Epoch   5: Training Loss = 0.47622  Validation Loss = 0.76694 f1= 0.69413\n",
            "Epoch   6: Training Loss = 0.44980  Validation Loss = 0.80507 f1= 0.68536\n",
            "Epoch   7: Training Loss = 0.41546  Validation Loss = 0.83158 f1= 0.67134\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.3526\t 70.2347\t 73.6220\t 1065\n",
            "label 1 | 47.5352\t 45.6081\t 46.5517\t 296\n",
            "label 2 | 62.9486\t 70.4669\t 66.4959\t 921\n",
            "micro   | 67.1341\t 67.1341\t 67.1341\t -\n",
            "[0.73622047 0.46551724 0.66495902]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.73829  Validation Loss = 0.68471 f1= 0.70903\n",
            "Epoch   1: Training Loss = 0.63778  Validation Loss = 0.67235 f1= 0.70947\n",
            "Epoch   2: Training Loss = 0.56835  Validation Loss = 0.72797 f1= 0.70684\n",
            "Epoch   3: Training Loss = 0.50503  Validation Loss = 0.73815 f1= 0.68887\n",
            "Epoch   4: Training Loss = 0.45489  Validation Loss = 0.75264 f1= 0.69895\n",
            "Epoch   5: Training Loss = 0.41510  Validation Loss = 0.76564 f1= 0.69106\n",
            "Epoch   6: Training Loss = 0.38214  Validation Loss = 0.88662 f1= 0.69939\n",
            "Epoch   7: Training Loss = 0.35935  Validation Loss = 0.87292 f1= 0.68931\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.1563\t 78.4038\t 76.2209\t 1065\n",
            "label 1 | 48.7288\t 38.8514\t 43.2331\t 296\n",
            "label 2 | 67.7174\t 67.6439\t 67.6806\t 921\n",
            "micro   | 68.9308\t 68.9308\t 68.9308\t -\n",
            "[0.76220904 0.43233083 0.67680608]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.81228  Validation Loss = 0.70917 f1= 0.68580\n",
            "Epoch   1: Training Loss = 0.67765  Validation Loss = 0.68184 f1= 0.69544\n",
            "Epoch   2: Training Loss = 0.61485  Validation Loss = 0.70330 f1= 0.70070\n",
            "Epoch   3: Training Loss = 0.56817  Validation Loss = 0.69842 f1= 0.70114\n",
            "Epoch   4: Training Loss = 0.51966  Validation Loss = 0.73344 f1= 0.69544\n",
            "Epoch   5: Training Loss = 0.48695  Validation Loss = 0.74465 f1= 0.69982\n",
            "Epoch   6: Training Loss = 0.44615  Validation Loss = 0.79379 f1= 0.69238\n",
            "Epoch   7: Training Loss = 0.42164  Validation Loss = 0.80981 f1= 0.69413\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.8889\t 73.3333\t 76.0097\t 1065\n",
            "label 1 | 47.2222\t 51.6892\t 49.3548\t 296\n",
            "label 2 | 67.1488\t 70.5755\t 68.8195\t 921\n",
            "micro   | 69.4128\t 69.4128\t 69.4128\t -\n",
            "[0.76009732 0.49354839 0.68819481]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.73828  Validation Loss = 0.68204 f1= 0.71122\n",
            "Epoch   1: Training Loss = 0.63706  Validation Loss = 0.67260 f1= 0.70947\n",
            "Epoch   2: Training Loss = 0.56772  Validation Loss = 0.71571 f1= 0.70640\n",
            "Epoch   3: Training Loss = 0.50899  Validation Loss = 0.73155 f1= 0.69807\n",
            "Epoch   4: Training Loss = 0.46823  Validation Loss = 0.73227 f1= 0.70465\n",
            "Epoch   5: Training Loss = 0.41898  Validation Loss = 0.77957 f1= 0.69457\n",
            "Epoch   6: Training Loss = 0.39407  Validation Loss = 0.82317 f1= 0.70815\n",
            "Epoch   7: Training Loss = 0.37560  Validation Loss = 0.84250 f1= 0.69939\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.9086\t 76.6197\t 76.7639\t 1065\n",
            "label 1 | 49.4845\t 48.6486\t 49.0630\t 296\n",
            "label 2 | 68.3871\t 69.0554\t 68.7196\t 921\n",
            "micro   | 69.9387\t 69.9387\t 69.9387\t -\n",
            "[0.76763876 0.49063032 0.68719611]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.81384  Validation Loss = 0.72158 f1= 0.67660\n",
            "Epoch   1: Training Loss = 0.68487  Validation Loss = 0.69561 f1= 0.70070\n",
            "Epoch   2: Training Loss = 0.62258  Validation Loss = 0.68646 f1= 0.69982\n",
            "Epoch   3: Training Loss = 0.57385  Validation Loss = 0.69840 f1= 0.70903\n",
            "Epoch   4: Training Loss = 0.53599  Validation Loss = 0.71529 f1= 0.69413\n",
            "Epoch   5: Training Loss = 0.50051  Validation Loss = 0.73525 f1= 0.70158\n",
            "Epoch   6: Training Loss = 0.47322  Validation Loss = 0.76455 f1= 0.69632\n",
            "Epoch   7: Training Loss = 0.44616  Validation Loss = 0.79385 f1= 0.68186\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 79.0816\t 72.7700\t 75.7946\t 1065\n",
            "label 1 | 43.7126\t 49.3243\t 46.3492\t 296\n",
            "label 2 | 65.5992\t 68.9468\t 67.2313\t 921\n",
            "micro   | 68.1858\t 68.1858\t 68.1858\t -\n",
            "[0.75794621 0.46349206 0.67231339]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 64, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.74054  Validation Loss = 0.68434 f1= 0.70377\n",
            "Epoch   1: Training Loss = 0.64499  Validation Loss = 0.67285 f1= 0.70947\n",
            "Epoch   2: Training Loss = 0.58764  Validation Loss = 0.72460 f1= 0.70333\n",
            "Epoch   3: Training Loss = 0.53428  Validation Loss = 0.69975 f1= 0.70990\n",
            "Epoch   4: Training Loss = 0.49049  Validation Loss = 0.74221 f1= 0.70552\n",
            "Epoch   5: Training Loss = 0.45563  Validation Loss = 0.76816 f1= 0.69588\n",
            "Epoch   6: Training Loss = 0.42800  Validation Loss = 0.82613 f1= 0.69763\n",
            "Epoch   7: Training Loss = 0.42019  Validation Loss = 0.84936 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.3644\t 71.0798\t 74.5446\t 1065\n",
            "label 1 | 46.8864\t 43.2432\t 44.9912\t 296\n",
            "label 2 | 63.9501\t 72.4213\t 67.9226\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.74544559 0.44991213 0.67922607]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.83033  Validation Loss = 0.71792 f1= 0.67748\n",
            "Epoch   1: Training Loss = 0.67829  Validation Loss = 0.67859 f1= 0.70640\n",
            "Epoch   2: Training Loss = 0.59426  Validation Loss = 0.68663 f1= 0.70421\n",
            "Epoch   3: Training Loss = 0.50814  Validation Loss = 0.71858 f1= 0.69982\n",
            "Epoch   4: Training Loss = 0.44570  Validation Loss = 0.77304 f1= 0.70684\n",
            "Epoch   5: Training Loss = 0.38276  Validation Loss = 0.81741 f1= 0.69369\n",
            "Epoch   6: Training Loss = 0.33785  Validation Loss = 0.91317 f1= 0.68887\n",
            "Epoch   7: Training Loss = 0.30624  Validation Loss = 0.94291 f1= 0.68493\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.9398\t 75.8685\t 75.9042\t 1065\n",
            "label 1 | 46.3320\t 40.5405\t 43.2432\t 296\n",
            "label 2 | 66.2148\t 68.9468\t 67.5532\t 921\n",
            "micro   | 68.4926\t 68.4926\t 68.4926\t -\n",
            "[0.7590418  0.43243243 0.67553191]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.75416  Validation Loss = 0.69972 f1= 0.69150\n",
            "Epoch   1: Training Loss = 0.63781  Validation Loss = 0.66002 f1= 0.71209\n",
            "Epoch   2: Training Loss = 0.55759  Validation Loss = 0.67199 f1= 0.71166\n",
            "Epoch   3: Training Loss = 0.47001  Validation Loss = 0.71994 f1= 0.70377\n",
            "Epoch   4: Training Loss = 0.39458  Validation Loss = 0.77967 f1= 0.68755\n",
            "Epoch   5: Training Loss = 0.32952  Validation Loss = 0.84877 f1= 0.69150\n",
            "Epoch   6: Training Loss = 0.26784  Validation Loss = 1.01243 f1= 0.68843\n",
            "Epoch   7: Training Loss = 0.23737  Validation Loss = 1.06407 f1= 0.67923\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.9293\t 74.6479\t 74.7883\t 1065\n",
            "label 1 | 50.0000\t 44.9324\t 47.3310\t 296\n",
            "label 2 | 65.1309\t 67.5353\t 66.3113\t 921\n",
            "micro   | 67.9229\t 67.9229\t 67.9229\t -\n",
            "[0.74788335 0.47330961 0.66311301]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.83151  Validation Loss = 0.71380 f1= 0.68230\n",
            "Epoch   1: Training Loss = 0.67949  Validation Loss = 0.67922 f1= 0.70465\n",
            "Epoch   2: Training Loss = 0.60208  Validation Loss = 0.67998 f1= 0.71034\n",
            "Epoch   3: Training Loss = 0.52577  Validation Loss = 0.71270 f1= 0.69807\n",
            "Epoch   4: Training Loss = 0.46967  Validation Loss = 0.74475 f1= 0.69150\n",
            "Epoch   5: Training Loss = 0.42302  Validation Loss = 0.79724 f1= 0.67134\n",
            "Epoch   6: Training Loss = 0.37644  Validation Loss = 0.88239 f1= 0.68186\n",
            "Epoch   7: Training Loss = 0.34948  Validation Loss = 0.85471 f1= 0.70245\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.7671\t 75.5869\t 77.1442\t 1065\n",
            "label 1 | 53.3040\t 40.8784\t 46.2715\t 296\n",
            "label 2 | 65.5373\t 73.5071\t 69.2938\t 921\n",
            "micro   | 70.2454\t 70.2454\t 70.2454\t -\n",
            "[0.77144226 0.46271511 0.69293756]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.75612  Validation Loss = 0.70523 f1= 0.68755\n",
            "Epoch   1: Training Loss = 0.64297  Validation Loss = 0.66541 f1= 0.71253\n",
            "Epoch   2: Training Loss = 0.56851  Validation Loss = 0.66989 f1= 0.69851\n",
            "Epoch   3: Training Loss = 0.48624  Validation Loss = 0.70743 f1= 0.69763\n",
            "Epoch   4: Training Loss = 0.42017  Validation Loss = 0.75739 f1= 0.70070\n",
            "Epoch   5: Training Loss = 0.36202  Validation Loss = 0.83294 f1= 0.68931\n",
            "Epoch   6: Training Loss = 0.30689  Validation Loss = 0.93516 f1= 0.69238\n",
            "Epoch   7: Training Loss = 0.27581  Validation Loss = 0.98737 f1= 0.67704\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.5051\t 75.0235\t 74.2565\t 1065\n",
            "label 1 | 50.0000\t 40.8784\t 44.9814\t 296\n",
            "label 2 | 65.5824\t 67.8610\t 66.7022\t 921\n",
            "micro   | 67.7038\t 67.7038\t 67.7038\t -\n",
            "[0.74256506 0.44981413 0.66702241]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.83290  Validation Loss = 0.72009 f1= 0.68098\n",
            "Epoch   1: Training Loss = 0.68875  Validation Loss = 0.67854 f1= 0.69939\n",
            "Epoch   2: Training Loss = 0.61887  Validation Loss = 0.67862 f1= 0.70640\n",
            "Epoch   3: Training Loss = 0.54199  Validation Loss = 0.70873 f1= 0.70026\n",
            "Epoch   4: Training Loss = 0.49526  Validation Loss = 0.73292 f1= 0.68887\n",
            "Epoch   5: Training Loss = 0.44367  Validation Loss = 0.78569 f1= 0.70202\n",
            "Epoch   6: Training Loss = 0.40960  Validation Loss = 0.85940 f1= 0.69500\n",
            "Epoch   7: Training Loss = 0.37641  Validation Loss = 0.80967 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.3234\t 74.4601\t 75.3802\t 1065\n",
            "label 1 | 45.7143\t 48.6486\t 47.1358\t 296\n",
            "label 2 | 66.2716\t 66.7752\t 66.5224\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.75380228 0.47135843 0.66522445]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.75585  Validation Loss = 0.70571 f1= 0.68580\n",
            "Epoch   1: Training Loss = 0.64620  Validation Loss = 0.67010 f1= 0.70771\n",
            "Epoch   2: Training Loss = 0.57704  Validation Loss = 0.66826 f1= 0.70421\n",
            "Epoch   3: Training Loss = 0.50044  Validation Loss = 0.69480 f1= 0.69720\n",
            "Epoch   4: Training Loss = 0.43702  Validation Loss = 0.74899 f1= 0.69982\n",
            "Epoch   5: Training Loss = 0.37940  Validation Loss = 0.82403 f1= 0.68142\n",
            "Epoch   6: Training Loss = 0.33560  Validation Loss = 0.93194 f1= 0.68273\n",
            "Epoch   7: Training Loss = 0.31104  Validation Loss = 1.01131 f1= 0.67704\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.7081\t 76.3380\t 75.0000\t 1065\n",
            "label 1 | 46.8619\t 37.8378\t 41.8692\t 296\n",
            "label 2 | 65.9574\t 67.3181\t 66.6308\t 921\n",
            "micro   | 67.7038\t 67.7038\t 67.7038\t -\n",
            "[0.75       0.41869159 0.66630844]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.82957  Validation Loss = 0.71721 f1= 0.68186\n",
            "Epoch   1: Training Loss = 0.68609  Validation Loss = 0.68465 f1= 0.69632\n",
            "Epoch   2: Training Loss = 0.62334  Validation Loss = 0.68362 f1= 0.70596\n",
            "Epoch   3: Training Loss = 0.55278  Validation Loss = 0.70664 f1= 0.69939\n",
            "Epoch   4: Training Loss = 0.50625  Validation Loss = 0.73833 f1= 0.69720\n",
            "Epoch   5: Training Loss = 0.46130  Validation Loss = 0.75933 f1= 0.69544\n",
            "Epoch   6: Training Loss = 0.43204  Validation Loss = 0.81341 f1= 0.69325\n",
            "Epoch   7: Training Loss = 0.39228  Validation Loss = 0.83783 f1= 0.68273\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.5915\t 78.4977\t 75.9655\t 1065\n",
            "label 1 | 48.6486\t 48.6486\t 48.6486\t 296\n",
            "label 2 | 68.0000\t 62.7579\t 65.2739\t 921\n",
            "micro   | 68.2734\t 68.2734\t 68.2734\t -\n",
            "[0.7596547  0.48648649 0.65273857]\n",
            "num_layers: 2,hidden_size: 32, batch_size: 128, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.75699  Validation Loss = 0.70608 f1= 0.68843\n",
            "Epoch   1: Training Loss = 0.64898  Validation Loss = 0.65989 f1= 0.70684\n",
            "Epoch   2: Training Loss = 0.58351  Validation Loss = 0.67287 f1= 0.70684\n",
            "Epoch   3: Training Loss = 0.51434  Validation Loss = 0.70970 f1= 0.70158\n",
            "Epoch   4: Training Loss = 0.45664  Validation Loss = 0.71791 f1= 0.69763\n",
            "Epoch   5: Training Loss = 0.40711  Validation Loss = 0.79884 f1= 0.69544\n",
            "Epoch   6: Training Loss = 0.35786  Validation Loss = 0.87218 f1= 0.70070\n",
            "Epoch   7: Training Loss = 0.32011  Validation Loss = 0.91087 f1= 0.68712\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.0226\t 77.8404\t 76.4055\t 1065\n",
            "label 1 | 47.0588\t 40.5405\t 43.5572\t 296\n",
            "label 2 | 67.1367\t 67.2096\t 67.1731\t 921\n",
            "micro   | 68.7117\t 68.7117\t 68.7117\t -\n",
            "[0.7640553  0.43557169 0.67173087]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.83661  Validation Loss = 0.72236 f1= 0.68668\n",
            "Epoch   1: Training Loss = 0.67959  Validation Loss = 0.71801 f1= 0.68975\n",
            "Epoch   2: Training Loss = 0.61742  Validation Loss = 0.72187 f1= 0.68624\n",
            "Epoch   3: Training Loss = 0.55817  Validation Loss = 0.72872 f1= 0.69369\n",
            "Epoch   4: Training Loss = 0.51016  Validation Loss = 0.75180 f1= 0.69500\n",
            "Epoch   5: Training Loss = 0.47010  Validation Loss = 0.78828 f1= 0.67835\n",
            "Epoch   6: Training Loss = 0.46036  Validation Loss = 0.79814 f1= 0.68317\n",
            "Epoch   7: Training Loss = 0.43051  Validation Loss = 0.81815 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.8979\t 75.3991\t 75.6477\t 1065\n",
            "label 1 | 46.7213\t 38.5135\t 42.2222\t 296\n",
            "label 2 | 64.7959\t 68.9468\t 66.8069\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.75647668 0.42222222 0.66806944]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.74567  Validation Loss = 0.69621 f1= 0.70508\n",
            "Epoch   1: Training Loss = 0.63532  Validation Loss = 0.70023 f1= 0.69676\n",
            "Epoch   2: Training Loss = 0.56049  Validation Loss = 0.69971 f1= 0.70640\n",
            "Epoch   3: Training Loss = 0.49834  Validation Loss = 0.73654 f1= 0.70026\n",
            "Epoch   4: Training Loss = 0.45358  Validation Loss = 0.76150 f1= 0.68054\n",
            "Epoch   5: Training Loss = 0.45667  Validation Loss = 0.81507 f1= 0.68536\n",
            "Epoch   6: Training Loss = 0.48495  Validation Loss = 0.79440 f1= 0.68931\n",
            "Epoch   7: Training Loss = 0.49355  Validation Loss = 0.77349 f1= 0.68449\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.8865\t 79.4366\t 76.5611\t 1065\n",
            "label 1 | 44.8276\t 30.7432\t 36.4729\t 296\n",
            "label 2 | 66.9165\t 67.8610\t 67.3854\t 921\n",
            "micro   | 68.4487\t 68.4487\t 68.4487\t -\n",
            "[0.76561086 0.36472946 0.67385445]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.84877  Validation Loss = 0.71660 f1= 0.68273\n",
            "Epoch   1: Training Loss = 0.68382  Validation Loss = 0.71456 f1= 0.69457\n",
            "Epoch   2: Training Loss = 0.62059  Validation Loss = 0.71817 f1= 0.68843\n",
            "Epoch   3: Training Loss = 0.56474  Validation Loss = 0.74291 f1= 0.68712\n",
            "Epoch   4: Training Loss = 0.53641  Validation Loss = 0.73755 f1= 0.69807\n",
            "Epoch   5: Training Loss = 0.51032  Validation Loss = 0.77625 f1= 0.68712\n",
            "Epoch   6: Training Loss = 0.48823  Validation Loss = 0.76884 f1= 0.68054\n",
            "Epoch   7: Training Loss = 0.48029  Validation Loss = 0.80679 f1= 0.66696\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.3063\t 75.0235\t 75.1646\t 1065\n",
            "label 1 | 41.4439\t 52.3649\t 46.2687\t 296\n",
            "label 2 | 67.0602\t 61.6721\t 64.2534\t 921\n",
            "micro   | 66.6959\t 66.6959\t 66.6959\t -\n",
            "[0.75164628 0.46268657 0.64253394]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.74680  Validation Loss = 0.69297 f1= 0.69895\n",
            "Epoch   1: Training Loss = 0.63749  Validation Loss = 0.67921 f1= 0.70727\n",
            "Epoch   2: Training Loss = 0.56659  Validation Loss = 0.74102 f1= 0.69281\n",
            "Epoch   3: Training Loss = 0.50761  Validation Loss = 0.74453 f1= 0.70245\n",
            "Epoch   4: Training Loss = 0.48890  Validation Loss = 0.73730 f1= 0.69413\n",
            "Epoch   5: Training Loss = 0.47408  Validation Loss = 0.78498 f1= 0.70070\n",
            "Epoch   6: Training Loss = 0.45526  Validation Loss = 0.82145 f1= 0.67572\n",
            "Epoch   7: Training Loss = 0.50210  Validation Loss = 0.81816 f1= 0.68405\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 72.1477\t 80.7512\t 76.2074\t 1065\n",
            "label 1 | 52.2388\t 23.6486\t 32.5581\t 296\n",
            "label 2 | 66.0042\t 68.5125\t 67.2349\t 921\n",
            "micro   | 68.4049\t 68.4049\t 68.4049\t -\n",
            "[0.76207355 0.3255814  0.67234949]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.84774  Validation Loss = 0.72868 f1= 0.68624\n",
            "Epoch   1: Training Loss = 0.69325  Validation Loss = 0.72940 f1= 0.69238\n",
            "Epoch   2: Training Loss = 0.64327  Validation Loss = 0.69769 f1= 0.69544\n",
            "Epoch   3: Training Loss = 0.59744  Validation Loss = 0.70746 f1= 0.68361\n",
            "Epoch   4: Training Loss = 0.57067  Validation Loss = 0.72032 f1= 0.69500\n",
            "Epoch   5: Training Loss = 0.55049  Validation Loss = 0.73599 f1= 0.69238\n",
            "Epoch   6: Training Loss = 0.53793  Validation Loss = 0.74021 f1= 0.68755\n",
            "Epoch   7: Training Loss = 0.53940  Validation Loss = 0.75666 f1= 0.67178\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.4374\t 77.6526\t 76.0110\t 1065\n",
            "label 1 | 41.3793\t 52.7027\t 46.3596\t 296\n",
            "label 2 | 69.2695\t 59.7177\t 64.1399\t 921\n",
            "micro   | 67.1779\t 67.1779\t 67.1779\t -\n",
            "[0.76011029 0.46359584 0.64139942]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.74846  Validation Loss = 0.69430 f1= 0.70289\n",
            "Epoch   1: Training Loss = 0.64027  Validation Loss = 0.67590 f1= 0.70815\n",
            "Epoch   2: Training Loss = 0.57724  Validation Loss = 0.67671 f1= 0.71648\n",
            "Epoch   3: Training Loss = 0.52407  Validation Loss = 0.72811 f1= 0.70026\n",
            "Epoch   4: Training Loss = 0.50464  Validation Loss = 0.74183 f1= 0.69632\n",
            "Epoch   5: Training Loss = 0.47266  Validation Loss = 0.76965 f1= 0.69851\n",
            "Epoch   6: Training Loss = 0.48664  Validation Loss = 0.79113 f1= 0.67441\n",
            "Epoch   7: Training Loss = 0.54810  Validation Loss = 0.77175 f1= 0.69851\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.0892\t 77.0892\t 77.0892\t 1065\n",
            "label 1 | 53.0726\t 32.0946\t 40.0000\t 296\n",
            "label 2 | 65.3179\t 73.6156\t 69.2190\t 921\n",
            "micro   | 69.8510\t 69.8510\t 69.8510\t -\n",
            "[0.77089202 0.4        0.69218989]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.78816  Validation Loss = 0.70399 f1= 0.68449\n",
            "Epoch   1: Training Loss = 0.66689  Validation Loss = 0.69873 f1= 0.70114\n",
            "Epoch   2: Training Loss = 0.62119  Validation Loss = 0.69415 f1= 0.70465\n",
            "Epoch   3: Training Loss = 0.57739  Validation Loss = 0.71828 f1= 0.69281\n",
            "Epoch   4: Training Loss = 0.54257  Validation Loss = 0.70484 f1= 0.69413\n",
            "Epoch   5: Training Loss = 0.51841  Validation Loss = 0.75932 f1= 0.68230\n",
            "Epoch   6: Training Loss = 0.50244  Validation Loss = 0.76199 f1= 0.66696\n",
            "Epoch   7: Training Loss = 0.48592  Validation Loss = 0.76840 f1= 0.68624\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.0913\t 76.1502\t 76.6179\t 1065\n",
            "label 1 | 45.8886\t 58.4459\t 51.4116\t 296\n",
            "label 2 | 68.2298\t 63.1922\t 65.6144\t 921\n",
            "micro   | 68.6240\t 68.6240\t 68.6240\t -\n",
            "[0.76617855 0.5141159  0.65614431]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 64, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.74992  Validation Loss = 0.68938 f1= 0.69807\n",
            "Epoch   1: Training Loss = 0.64596  Validation Loss = 0.68053 f1= 0.70859\n",
            "Epoch   2: Training Loss = 0.58847  Validation Loss = 0.70115 f1= 0.70640\n",
            "Epoch   3: Training Loss = 0.53821  Validation Loss = 0.72836 f1= 0.68843\n",
            "Epoch   4: Training Loss = 0.52413  Validation Loss = 0.74629 f1= 0.69281\n",
            "Epoch   5: Training Loss = 0.50177  Validation Loss = 0.77282 f1= 0.70026\n",
            "Epoch   6: Training Loss = 0.50777  Validation Loss = 0.76650 f1= 0.69851\n",
            "Epoch   7: Training Loss = 0.56671  Validation Loss = 0.80723 f1= 0.67791\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.3050\t 71.6432\t 74.3665\t 1065\n",
            "label 1 | 50.3448\t 24.6622\t 33.1066\t 296\n",
            "label 2 | 61.8261\t 77.1987\t 68.6625\t 921\n",
            "micro   | 67.7914\t 67.7914\t 67.7914\t -\n",
            "[0.74366472 0.33106576 0.68662482]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.80479  Validation Loss = 0.71073 f1= 0.69018\n",
            "Epoch   1: Training Loss = 0.66598  Validation Loss = 0.67690 f1= 0.71034\n",
            "Epoch   2: Training Loss = 0.57365  Validation Loss = 0.68260 f1= 0.71122\n",
            "Epoch   3: Training Loss = 0.48490  Validation Loss = 0.74009 f1= 0.70771\n",
            "Epoch   4: Training Loss = 0.40417  Validation Loss = 0.79684 f1= 0.68755\n",
            "Epoch   5: Training Loss = 0.35352  Validation Loss = 0.90036 f1= 0.69018\n",
            "Epoch   6: Training Loss = 0.31902  Validation Loss = 0.89909 f1= 0.68536\n",
            "Epoch   7: Training Loss = 0.28219  Validation Loss = 0.96263 f1= 0.68098\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.4661\t 75.3052\t 74.8833\t 1065\n",
            "label 1 | 48.2517\t 46.6216\t 47.4227\t 296\n",
            "label 2 | 66.8118\t 66.6667\t 66.7391\t 921\n",
            "micro   | 68.0982\t 68.0982\t 68.0982\t -\n",
            "[0.74883287 0.4742268  0.6673913 ]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.75475  Validation Loss = 0.69585 f1= 0.69939\n",
            "Epoch   1: Training Loss = 0.63795  Validation Loss = 0.68092 f1= 0.70377\n",
            "Epoch   2: Training Loss = 0.55235  Validation Loss = 0.69230 f1= 0.69763\n",
            "Epoch   3: Training Loss = 0.45000  Validation Loss = 0.77941 f1= 0.69588\n",
            "Epoch   4: Training Loss = 0.36698  Validation Loss = 0.85543 f1= 0.70202\n",
            "Epoch   5: Training Loss = 0.31958  Validation Loss = 0.93939 f1= 0.68536\n",
            "Epoch   6: Training Loss = 0.28096  Validation Loss = 0.93899 f1= 0.67441\n",
            "Epoch   7: Training Loss = 0.26355  Validation Loss = 1.01250 f1= 0.67222\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.3330\t 75.8685\t 75.0929\t 1065\n",
            "label 1 | 43.3333\t 39.5270\t 41.3428\t 296\n",
            "label 2 | 65.8378\t 66.1238\t 65.9805\t 921\n",
            "micro   | 67.2217\t 67.2217\t 67.2217\t -\n",
            "[0.75092937 0.41342756 0.65980498]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.80458  Validation Loss = 0.71324 f1= 0.69150\n",
            "Epoch   1: Training Loss = 0.66471  Validation Loss = 0.66945 f1= 0.70640\n",
            "Epoch   2: Training Loss = 0.57876  Validation Loss = 0.67949 f1= 0.71429\n",
            "Epoch   3: Training Loss = 0.49640  Validation Loss = 0.72974 f1= 0.71034\n",
            "Epoch   4: Training Loss = 0.43072  Validation Loss = 0.74611 f1= 0.69763\n",
            "Epoch   5: Training Loss = 0.37301  Validation Loss = 0.88221 f1= 0.69939\n",
            "Epoch   6: Training Loss = 0.34314  Validation Loss = 0.86212 f1= 0.69150\n",
            "Epoch   7: Training Loss = 0.30769  Validation Loss = 0.92020 f1= 0.70202\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 77.2814\t 76.3380\t 76.8068\t 1065\n",
            "label 1 | 52.0913\t 46.2838\t 49.0161\t 296\n",
            "label 2 | 67.4250\t 70.7926\t 69.0678\t 921\n",
            "micro   | 70.2016\t 70.2016\t 70.2016\t -\n",
            "[0.76806802 0.490161   0.69067797]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.75633  Validation Loss = 0.70063 f1= 0.69676\n",
            "Epoch   1: Training Loss = 0.64022  Validation Loss = 0.67098 f1= 0.70640\n",
            "Epoch   2: Training Loss = 0.55366  Validation Loss = 0.69667 f1= 0.70026\n",
            "Epoch   3: Training Loss = 0.46108  Validation Loss = 0.77509 f1= 0.69369\n",
            "Epoch   4: Training Loss = 0.38233  Validation Loss = 0.82249 f1= 0.70158\n",
            "Epoch   5: Training Loss = 0.32607  Validation Loss = 0.88184 f1= 0.69720\n",
            "Epoch   6: Training Loss = 0.29456  Validation Loss = 0.94515 f1= 0.68668\n",
            "Epoch   7: Training Loss = 0.26900  Validation Loss = 1.00647 f1= 0.67835\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.6530\t 76.1502\t 75.9008\t 1065\n",
            "label 1 | 46.0870\t 35.8108\t 40.3042\t 296\n",
            "label 2 | 64.3878\t 68.5125\t 66.3861\t 921\n",
            "micro   | 67.8352\t 67.8352\t 67.8352\t -\n",
            "[0.75900796 0.40304183 0.66386113]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.80974  Validation Loss = 0.71301 f1= 0.68931\n",
            "Epoch   1: Training Loss = 0.66850  Validation Loss = 0.67119 f1= 0.71604\n",
            "Epoch   2: Training Loss = 0.58778  Validation Loss = 0.69244 f1= 0.70158\n",
            "Epoch   3: Training Loss = 0.50575  Validation Loss = 0.73436 f1= 0.70727\n",
            "Epoch   4: Training Loss = 0.44209  Validation Loss = 0.75637 f1= 0.69106\n",
            "Epoch   5: Training Loss = 0.38782  Validation Loss = 0.86166 f1= 0.67090\n",
            "Epoch   6: Training Loss = 0.35477  Validation Loss = 0.89326 f1= 0.67134\n",
            "Epoch   7: Training Loss = 0.31625  Validation Loss = 0.94260 f1= 0.68273\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.5741\t 77.6526\t 77.1096\t 1065\n",
            "label 1 | 42.0245\t 46.2838\t 44.0514\t 296\n",
            "label 2 | 67.8082\t 64.4951\t 66.1102\t 921\n",
            "micro   | 68.2734\t 68.2734\t 68.2734\t -\n",
            "[0.77109557 0.44051447 0.66110184]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.75500  Validation Loss = 0.69038 f1= 0.69194\n",
            "Epoch   1: Training Loss = 0.64581  Validation Loss = 0.66549 f1= 0.71122\n",
            "Epoch   2: Training Loss = 0.56172  Validation Loss = 0.68800 f1= 0.70727\n",
            "Epoch   3: Training Loss = 0.48117  Validation Loss = 0.75725 f1= 0.70333\n",
            "Epoch   4: Training Loss = 0.40661  Validation Loss = 0.77930 f1= 0.69457\n",
            "Epoch   5: Training Loss = 0.35320  Validation Loss = 0.89176 f1= 0.68536\n",
            "Epoch   6: Training Loss = 0.32091  Validation Loss = 0.91770 f1= 0.68493\n",
            "Epoch   7: Training Loss = 0.30853  Validation Loss = 0.98452 f1= 0.67923\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.9405\t 76.9953\t 75.4370\t 1065\n",
            "label 1 | 44.8630\t 44.2568\t 44.5578\t 296\n",
            "label 2 | 67.9909\t 65.0380\t 66.4817\t 921\n",
            "micro   | 67.9229\t 67.9229\t 67.9229\t -\n",
            "[0.75436983 0.44557823 0.66481687]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.81139  Validation Loss = 0.72751 f1= 0.68317\n",
            "Epoch   1: Training Loss = 0.66889  Validation Loss = 0.68464 f1= 0.70289\n",
            "Epoch   2: Training Loss = 0.58528  Validation Loss = 0.68928 f1= 0.70202\n",
            "Epoch   3: Training Loss = 0.51417  Validation Loss = 0.70948 f1= 0.69895\n",
            "Epoch   4: Training Loss = 0.45987  Validation Loss = 0.71913 f1= 0.70333\n",
            "Epoch   5: Training Loss = 0.41369  Validation Loss = 0.81563 f1= 0.70070\n",
            "Epoch   6: Training Loss = 0.37527  Validation Loss = 0.84086 f1= 0.68098\n",
            "Epoch   7: Training Loss = 0.36737  Validation Loss = 0.87271 f1= 0.69194\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.8007\t 77.0892\t 76.9447\t 1065\n",
            "label 1 | 44.0860\t 41.5541\t 42.7826\t 296\n",
            "label 2 | 67.9872\t 68.9468\t 68.4636\t 921\n",
            "micro   | 69.1937\t 69.1937\t 69.1937\t -\n",
            "[0.76944705 0.42782609 0.68463612]\n",
            "num_layers: 2,hidden_size: 64, batch_size: 128, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.75550  Validation Loss = 0.70906 f1= 0.69457\n",
            "Epoch   1: Training Loss = 0.64412  Validation Loss = 0.69625 f1= 0.69895\n",
            "Epoch   2: Training Loss = 0.57012  Validation Loss = 0.67730 f1= 0.71166\n",
            "Epoch   3: Training Loss = 0.48473  Validation Loss = 0.76361 f1= 0.69632\n",
            "Epoch   4: Training Loss = 0.41119  Validation Loss = 0.79877 f1= 0.69062\n",
            "Epoch   5: Training Loss = 0.35250  Validation Loss = 0.85817 f1= 0.68493\n",
            "Epoch   6: Training Loss = 0.33064  Validation Loss = 0.96824 f1= 0.66959\n",
            "Epoch   7: Training Loss = 0.31208  Validation Loss = 0.95815 f1= 0.68493\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.9533\t 75.3052\t 75.1288\t 1065\n",
            "label 1 | 47.1429\t 44.5946\t 45.8333\t 296\n",
            "label 2 | 67.4893\t 68.2953\t 67.8899\t 921\n",
            "micro   | 68.4926\t 68.4926\t 68.4926\t -\n",
            "[0.75128806 0.45833333 0.67889908]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.81955  Validation Loss = 0.76096 f1= 0.67572\n",
            "Epoch   1: Training Loss = 0.69209  Validation Loss = 0.71958 f1= 0.68755\n",
            "Epoch   2: Training Loss = 0.62918  Validation Loss = 0.71862 f1= 0.68931\n",
            "Epoch   3: Training Loss = 0.60948  Validation Loss = 0.71369 f1= 0.67660\n",
            "Epoch   4: Training Loss = 0.58455  Validation Loss = 0.73022 f1= 0.68975\n",
            "Epoch   5: Training Loss = 0.54493  Validation Loss = 0.78327 f1= 0.68098\n",
            "Epoch   6: Training Loss = 0.54246  Validation Loss = 0.77120 f1= 0.67353\n",
            "Epoch   7: Training Loss = 0.53337  Validation Loss = 0.81656 f1= 0.65863\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 73.7041\t 73.4272\t 73.5654\t 1065\n",
            "label 1 | 42.1801\t 30.0676\t 35.1085\t 296\n",
            "label 2 | 62.5743\t 68.6211\t 65.4583\t 921\n",
            "micro   | 65.8633\t 65.8633\t 65.8633\t -\n",
            "[0.73565381 0.35108481 0.65458312]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.76776  Validation Loss = 0.71261 f1= 0.70508\n",
            "Epoch   1: Training Loss = 0.66381  Validation Loss = 0.79612 f1= 0.64636\n",
            "Epoch   2: Training Loss = 0.65050  Validation Loss = 0.71954 f1= 0.69325\n",
            "Epoch   3: Training Loss = 0.60433  Validation Loss = 0.72971 f1= 0.68142\n",
            "Epoch   4: Training Loss = 0.57511  Validation Loss = 0.76578 f1= 0.66696\n",
            "Epoch   5: Training Loss = 0.58801  Validation Loss = 0.80882 f1= 0.68580\n",
            "Epoch   6: Training Loss = 0.63145  Validation Loss = 0.74715 f1= 0.66784\n",
            "Epoch   7: Training Loss = 0.70883  Validation Loss = 0.74905 f1= 0.67485\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.4758\t 76.7136\t 75.5782\t 1065\n",
            "label 1 | 46.5409\t 25.0000\t 32.5275\t 296\n",
            "label 2 | 63.2554\t 70.4669\t 66.6667\t 921\n",
            "micro   | 67.4847\t 67.4847\t 67.4847\t -\n",
            "[0.75578168 0.32527473 0.66666667]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.80856  Validation Loss = 0.74283 f1= 0.68098\n",
            "Epoch   1: Training Loss = 0.68761  Validation Loss = 0.71848 f1= 0.67835\n",
            "Epoch   2: Training Loss = 0.63032  Validation Loss = 0.70789 f1= 0.69500\n",
            "Epoch   3: Training Loss = 0.57967  Validation Loss = 0.73080 f1= 0.68317\n",
            "Epoch   4: Training Loss = 0.55316  Validation Loss = 0.74074 f1= 0.67704\n",
            "Epoch   5: Training Loss = 0.52212  Validation Loss = 0.77237 f1= 0.68142\n",
            "Epoch   6: Training Loss = 0.50737  Validation Loss = 0.77814 f1= 0.67791\n",
            "Epoch   7: Training Loss = 0.49537  Validation Loss = 0.85653 f1= 0.68405\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 80.5889\t 69.3897\t 74.5711\t 1065\n",
            "label 1 | 52.1472\t 28.7162\t 37.0370\t 296\n",
            "label 2 | 61.3145\t 80.0217\t 69.4301\t 921\n",
            "micro   | 68.4049\t 68.4049\t 68.4049\t -\n",
            "[0.7457114  0.37037037 0.69430052]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.76487  Validation Loss = 0.70813 f1= 0.69281\n",
            "Epoch   1: Training Loss = 0.66768  Validation Loss = 0.73322 f1= 0.67791\n",
            "Epoch   2: Training Loss = 0.62079  Validation Loss = 0.72507 f1= 0.68011\n",
            "Epoch   3: Training Loss = 0.60680  Validation Loss = 0.78937 f1= 0.64505\n",
            "Epoch   4: Training Loss = 0.65471  Validation Loss = 0.77347 f1= 0.65951\n",
            "Epoch   5: Training Loss = 0.73674  Validation Loss = 0.78028 f1= 0.67704\n",
            "Epoch   6: Training Loss = 0.72195  Validation Loss = 0.77065 f1= 0.66039\n",
            "Epoch   7: Training Loss = 0.73768  Validation Loss = 0.75843 f1= 0.66696\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.9301\t 75.4930\t 75.2105\t 1065\n",
            "label 1 | 41.4013\t 21.9595\t 28.6976\t 296\n",
            "label 2 | 62.0722\t 70.9012\t 66.1936\t 921\n",
            "micro   | 66.6959\t 66.6959\t 66.6959\t -\n",
            "[0.75210477 0.28697572 0.66193614]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.80992  Validation Loss = 0.73869 f1= 0.68536\n",
            "Epoch   1: Training Loss = 0.68850  Validation Loss = 0.73892 f1= 0.66827\n",
            "Epoch   2: Training Loss = 0.63893  Validation Loss = 0.70787 f1= 0.68668\n",
            "Epoch   3: Training Loss = 0.60687  Validation Loss = 0.71966 f1= 0.69281\n",
            "Epoch   4: Training Loss = 0.59144  Validation Loss = 0.73861 f1= 0.68931\n",
            "Epoch   5: Training Loss = 0.58064  Validation Loss = 0.76808 f1= 0.69106\n",
            "Epoch   6: Training Loss = 0.56304  Validation Loss = 0.74182 f1= 0.68054\n",
            "Epoch   7: Training Loss = 0.54001  Validation Loss = 0.79925 f1= 0.68712\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 80.6002\t 70.6103\t 75.2753\t 1065\n",
            "label 1 | 51.8919\t 32.4324\t 39.9168\t 296\n",
            "label 2 | 61.8557\t 78.1759\t 69.0647\t 921\n",
            "micro   | 68.7117\t 68.7117\t 68.7117\t -\n",
            "[0.75275275 0.3991684  0.69064748]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.76527  Validation Loss = 0.72238 f1= 0.69720\n",
            "Epoch   1: Training Loss = 0.67218  Validation Loss = 0.82647 f1= 0.65469\n",
            "Epoch   2: Training Loss = 0.64698  Validation Loss = 0.72428 f1= 0.69500\n",
            "Epoch   3: Training Loss = 0.64701  Validation Loss = 0.75594 f1= 0.65644\n",
            "Epoch   4: Training Loss = 0.65692  Validation Loss = 0.77754 f1= 0.66433\n",
            "Epoch   5: Training Loss = 0.67119  Validation Loss = 0.75877 f1= 0.68054\n",
            "Epoch   6: Training Loss = 0.68012  Validation Loss = 0.70655 f1= 0.69281\n",
            "Epoch   7: Training Loss = 0.66365  Validation Loss = 0.71735 f1= 0.69194\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 75.0673\t 78.5915\t 76.7890\t 1065\n",
            "label 1 | 51.9126\t 32.0946\t 39.6660\t 296\n",
            "label 2 | 65.7520\t 70.2497\t 67.9265\t 921\n",
            "micro   | 69.1937\t 69.1937\t 69.1937\t -\n",
            "[0.76788991 0.39665971 0.67926509]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.83758  Validation Loss = 0.76442 f1= 0.67923\n",
            "Epoch   1: Training Loss = 0.72279  Validation Loss = 0.74154 f1= 0.67397\n",
            "Epoch   2: Training Loss = 0.66724  Validation Loss = 0.78425 f1= 0.63979\n",
            "Epoch   3: Training Loss = 0.63670  Validation Loss = 0.76027 f1= 0.68186\n",
            "Epoch   4: Training Loss = 0.61391  Validation Loss = 0.74676 f1= 0.67222\n",
            "Epoch   5: Training Loss = 0.59565  Validation Loss = 0.76037 f1= 0.67923\n",
            "Epoch   6: Training Loss = 0.61916  Validation Loss = 0.74167 f1= 0.67090\n",
            "Epoch   7: Training Loss = 0.64258  Validation Loss = 0.76085 f1= 0.66915\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 74.2857\t 78.1221\t 76.1556\t 1065\n",
            "label 1 | 41.0646\t 36.4865\t 38.6404\t 296\n",
            "label 2 | 65.2948\t 63.7351\t 64.5055\t 921\n",
            "micro   | 66.9150\t 66.9150\t 66.9150\t -\n",
            "[0.76155606 0.38640429 0.64505495]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 64, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.76680  Validation Loss = 0.71383 f1= 0.69150\n",
            "Epoch   1: Training Loss = 0.66829  Validation Loss = 0.72044 f1= 0.68361\n",
            "Epoch   2: Training Loss = 0.66893  Validation Loss = 0.72273 f1= 0.69238\n",
            "Epoch   3: Training Loss = 0.71204  Validation Loss = 0.74846 f1= 0.66082\n",
            "Epoch   4: Training Loss = 0.66948  Validation Loss = 0.73183 f1= 0.68712\n",
            "Epoch   5: Training Loss = 0.67814  Validation Loss = 0.83723 f1= 0.65951\n",
            "Epoch   6: Training Loss = 0.68855  Validation Loss = 0.71567 f1= 0.68230\n",
            "Epoch   7: Training Loss = 0.65030  Validation Loss = 0.73697 f1= 0.67353\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.6952\t 72.4883\t 75.4643\t 1065\n",
            "label 1 | 43.3594\t 37.5000\t 40.2174\t 296\n",
            "label 2 | 62.5837\t 71.0098\t 66.5310\t 921\n",
            "micro   | 67.3532\t 67.3532\t 67.3532\t -\n",
            "[0.75464321 0.40217391 0.66531027]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.89680  Validation Loss = 0.72650 f1= 0.67222\n",
            "Epoch   1: Training Loss = 0.69872  Validation Loss = 0.70729 f1= 0.68624\n",
            "Epoch   2: Training Loss = 0.60564  Validation Loss = 0.70120 f1= 0.70990\n",
            "Epoch   3: Training Loss = 0.52876  Validation Loss = 0.71648 f1= 0.70289\n",
            "Epoch   4: Training Loss = 0.47217  Validation Loss = 0.75303 f1= 0.69720\n",
            "Epoch   5: Training Loss = 0.45273  Validation Loss = 0.80162 f1= 0.70114\n",
            "Epoch   6: Training Loss = 0.45955  Validation Loss = 0.77206 f1= 0.67879\n",
            "Epoch   7: Training Loss = 0.51395  Validation Loss = 0.80992 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 81.9209\t 68.0751\t 74.3590\t 1065\n",
            "label 1 | 51.0204\t 25.3378\t 33.8600\t 296\n",
            "label 2 | 60.1600\t 81.6504\t 69.2768\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.74358974 0.33860045 0.69276831]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.76242  Validation Loss = 0.69837 f1= 0.69588\n",
            "Epoch   1: Training Loss = 0.64743  Validation Loss = 0.69359 f1= 0.70114\n",
            "Epoch   2: Training Loss = 0.54929  Validation Loss = 0.70488 f1= 0.70377\n",
            "Epoch   3: Training Loss = 0.46451  Validation Loss = 0.73334 f1= 0.70202\n",
            "Epoch   4: Training Loss = 0.44510  Validation Loss = 0.77400 f1= 0.69413\n",
            "Epoch   5: Training Loss = 0.45942  Validation Loss = 0.79761 f1= 0.68580\n",
            "Epoch   6: Training Loss = 0.52996  Validation Loss = 0.80755 f1= 0.66784\n",
            "Epoch   7: Training Loss = 0.60910  Validation Loss = 0.75215 f1= 0.67572\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.2518\t 70.6103\t 74.2349\t 1065\n",
            "label 1 | 48.9247\t 30.7432\t 37.7593\t 296\n",
            "label 2 | 61.5859\t 75.8958\t 67.9961\t 921\n",
            "micro   | 67.5723\t 67.5723\t 67.5723\t -\n",
            "[0.74234946 0.37759336 0.67996109]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.1, attention: False\n",
            "Epoch   0: Training Loss = 0.85193  Validation Loss = 0.73770 f1= 0.68405\n",
            "Epoch   1: Training Loss = 0.68851  Validation Loss = 0.70561 f1= 0.69676\n",
            "Epoch   2: Training Loss = 0.60259  Validation Loss = 0.72382 f1= 0.70202\n",
            "Epoch   3: Training Loss = 0.52780  Validation Loss = 0.71632 f1= 0.69325\n",
            "Epoch   4: Training Loss = 0.44804  Validation Loss = 0.75752 f1= 0.68887\n",
            "Epoch   5: Training Loss = 0.40548  Validation Loss = 0.80408 f1= 0.67791\n",
            "Epoch   6: Training Loss = 0.36846  Validation Loss = 0.83215 f1= 0.68361\n",
            "Epoch   7: Training Loss = 0.33359  Validation Loss = 0.90819 f1= 0.67704\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 80.1093\t 68.8263\t 74.0404\t 1065\n",
            "label 1 | 42.2741\t 48.9865\t 45.3834\t 296\n",
            "label 2 | 65.1367\t 72.4213\t 68.5861\t 921\n",
            "micro   | 67.7038\t 67.7038\t 67.7038\t -\n",
            "[0.74040404 0.45383412 0.68586118]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.1, attention: True\n",
            "Epoch   0: Training Loss = 0.76167  Validation Loss = 0.69875 f1= 0.69720\n",
            "Epoch   1: Training Loss = 0.65313  Validation Loss = 0.69730 f1= 0.70465\n",
            "Epoch   2: Training Loss = 0.55291  Validation Loss = 0.71342 f1= 0.71166\n",
            "Epoch   3: Training Loss = 0.47892  Validation Loss = 0.75899 f1= 0.69895\n",
            "Epoch   4: Training Loss = 0.46032  Validation Loss = 0.76470 f1= 0.69062\n",
            "Epoch   5: Training Loss = 0.47336  Validation Loss = 0.77760 f1= 0.70158\n",
            "Epoch   6: Training Loss = 0.55503  Validation Loss = 0.78121 f1= 0.68624\n",
            "Epoch   7: Training Loss = 0.57718  Validation Loss = 0.76376 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 76.3462\t 74.5540\t 75.4394\t 1065\n",
            "label 1 | 49.6815\t 26.3514\t 34.4371\t 296\n",
            "label 2 | 62.6728\t 73.8328\t 67.7966\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.7543943  0.34437086 0.6779661 ]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.2, attention: False\n",
            "Epoch   0: Training Loss = 0.90915  Validation Loss = 0.76261 f1= 0.67528\n",
            "Epoch   1: Training Loss = 0.71700  Validation Loss = 0.71808 f1= 0.69325\n",
            "Epoch   2: Training Loss = 0.62996  Validation Loss = 0.70136 f1= 0.70114\n",
            "Epoch   3: Training Loss = 0.56682  Validation Loss = 0.71889 f1= 0.70377\n",
            "Epoch   4: Training Loss = 0.50920  Validation Loss = 0.73300 f1= 0.68449\n",
            "Epoch   5: Training Loss = 0.47539  Validation Loss = 0.81166 f1= 0.67309\n",
            "Epoch   6: Training Loss = 0.46064  Validation Loss = 0.81252 f1= 0.66959\n",
            "Epoch   7: Training Loss = 0.44646  Validation Loss = 0.86672 f1= 0.67397\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 81.5205\t 65.4460\t 72.6042\t 1065\n",
            "label 1 | 48.2906\t 38.1757\t 42.6415\t 296\n",
            "label 2 | 61.0226\t 79.0445\t 68.8742\t 921\n",
            "micro   | 67.3970\t 67.3970\t 67.3970\t -\n",
            "[0.72604167 0.42641509 0.68874172]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.2, attention: True\n",
            "Epoch   0: Training Loss = 0.76281  Validation Loss = 0.69871 f1= 0.69763\n",
            "Epoch   1: Training Loss = 0.65333  Validation Loss = 0.69148 f1= 0.70465\n",
            "Epoch   2: Training Loss = 0.56363  Validation Loss = 0.73266 f1= 0.70333\n",
            "Epoch   3: Training Loss = 0.50264  Validation Loss = 0.73077 f1= 0.70508\n",
            "Epoch   4: Training Loss = 0.47841  Validation Loss = 0.74884 f1= 0.68931\n",
            "Epoch   5: Training Loss = 0.51227  Validation Loss = 0.79358 f1= 0.67660\n",
            "Epoch   6: Training Loss = 0.52240  Validation Loss = 0.76739 f1= 0.69106\n",
            "Epoch   7: Training Loss = 0.54866  Validation Loss = 0.76921 f1= 0.69106\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 80.1268\t 71.1737\t 75.3854\t 1065\n",
            "label 1 | 48.7805\t 33.7838\t 39.9202\t 296\n",
            "label 2 | 63.5721\t 78.0673\t 70.0780\t 921\n",
            "micro   | 69.1060\t 69.1060\t 69.1060\t -\n",
            "[0.7538538  0.3992016  0.70077973]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.3, attention: False\n",
            "Epoch   0: Training Loss = 0.89814  Validation Loss = 0.73406 f1= 0.67879\n",
            "Epoch   1: Training Loss = 0.70975  Validation Loss = 0.72596 f1= 0.67046\n",
            "Epoch   2: Training Loss = 0.63213  Validation Loss = 0.72351 f1= 0.69281\n",
            "Epoch   3: Training Loss = 0.57468  Validation Loss = 0.71570 f1= 0.68843\n",
            "Epoch   4: Training Loss = 0.51339  Validation Loss = 0.73916 f1= 0.67879\n",
            "Epoch   5: Training Loss = 0.49721  Validation Loss = 0.78774 f1= 0.66608\n",
            "Epoch   6: Training Loss = 0.46997  Validation Loss = 0.82236 f1= 0.67222\n",
            "Epoch   7: Training Loss = 0.46710  Validation Loss = 0.81087 f1= 0.67441\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 79.2696\t 69.2958\t 73.9479\t 1065\n",
            "label 1 | 46.0630\t 39.5270\t 42.5455\t 296\n",
            "label 2 | 62.3519\t 74.2671\t 67.7899\t 921\n",
            "micro   | 67.4408\t 67.4408\t 67.4408\t -\n",
            "[0.73947896 0.42545455 0.67789891]\n",
            "num_layers: 2,hidden_size: 128, batch_size: 128, dropout: 0.3, attention: True\n",
            "Epoch   0: Training Loss = 0.76278  Validation Loss = 0.69634 f1= 0.69895\n",
            "Epoch   1: Training Loss = 0.65745  Validation Loss = 0.69863 f1= 0.69763\n",
            "Epoch   2: Training Loss = 0.57155  Validation Loss = 0.69119 f1= 0.70640\n",
            "Epoch   3: Training Loss = 0.52678  Validation Loss = 0.74394 f1= 0.69720\n",
            "Epoch   4: Training Loss = 0.53317  Validation Loss = 0.79803 f1= 0.67441\n",
            "Epoch   5: Training Loss = 0.58622  Validation Loss = 0.74936 f1= 0.68449\n",
            "Epoch   6: Training Loss = 0.54659  Validation Loss = 0.75902 f1= 0.68273\n",
            "Epoch   7: Training Loss = 0.53327  Validation Loss = 0.77419 f1= 0.68011\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 79.0374\t 69.3897\t 73.9000\t 1065\n",
            "label 1 | 50.5682\t 30.0676\t 37.7119\t 296\n",
            "label 2 | 61.8275\t 78.6102\t 69.2161\t 921\n",
            "micro   | 68.0105\t 68.0105\t 68.0105\t -\n",
            "[0.739      0.37711864 0.69216061]\n",
            "num_layers: 3,hidden_size: 32, batch_size: 64, dropout: 0.0, attention: False\n",
            "Epoch   0: Training Loss = 0.83768  Validation Loss = 0.77917 f1= 0.66959\n",
            "Epoch   1: Training Loss = 0.71542  Validation Loss = 0.70337 f1= 0.67309\n",
            "Epoch   2: Training Loss = 0.65049  Validation Loss = 0.70343 f1= 0.69369\n",
            "Epoch   3: Training Loss = 0.59763  Validation Loss = 0.72049 f1= 0.68405\n",
            "Epoch   4: Training Loss = 0.55272  Validation Loss = 0.73351 f1= 0.68580\n",
            "Epoch   5: Training Loss = 0.52668  Validation Loss = 0.75537 f1= 0.67748\n",
            "Epoch   6: Training Loss = 0.50329  Validation Loss = 0.74734 f1= 0.69062\n",
            "Epoch   7: Training Loss = 0.47884  Validation Loss = 0.77337 f1= 0.69763\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "---------------------------------------------------------------\n",
            "label 0 | 78.9527\t 73.6150\t 76.1905\t 1065\n",
            "label 1 | 50.5495\t 46.6216\t 48.5062\t 296\n",
            "label 2 | 65.9449\t 72.7470\t 69.1791\t 921\n",
            "micro   | 69.7634\t 69.7634\t 69.7634\t -\n",
            "[0.76190476 0.48506151 0.69179143]\n",
            "num_layers: 3,hidden_size: 32, batch_size: 64, dropout: 0.0, attention: True\n",
            "Epoch   0: Training Loss = 0.75485  Validation Loss = 0.72370 f1= 0.68186\n",
            "Epoch   1: Training Loss = 0.65670  Validation Loss = 0.70115 f1= 0.69588\n",
            "Epoch   2: Training Loss = 0.58750  Validation Loss = 0.70514 f1= 0.70333\n",
            "Epoch   3: Training Loss = 0.52750  Validation Loss = 0.73863 f1= 0.68931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(params, loss)"
      ],
      "metadata": {
        "id": "bDtKeg5xMwGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DCj0ZOdKigS"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EpcCOTShpJAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "a7c594f2-1c63-4f76-b515-41c33fbaefee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c/DIouyj45kAEGDcokLIgpoggiigEaRoIIbMShqcIsxhJhFrkavJq6omKviDRoDUVFBRBQQxPgTlQFUliCICgzrgOwKMvP8/uiaoYFZuofpqe7i+3696jVVp6qrnukX83BOnTqnzN0REYmiamEHICKSKkpwIhJZSnAiEllKcCISWUpwIhJZNcIOIF5WVpa3bNky7DDS1vy5c8MOIe3lZGWFHUJaW79lC1u+/dYO5Bw9e/b0/Pz8hI7Nzc19y917Hsj1DkRaJbiWLVsye/bssMNIW23q1Qs7hLR3z4ABYYeQ1oaOGXPA58jPz0/479TMQv0fJ60SnIhkisx4flYJTkSS5l4YdggJUYITkSQ5qsGJSGRlyhBPJTgRqQAlOBGJLCU4EYkoNVFFJKIcUC+qiESQu2pwIhJpSnAiEllKcCISSa4mqohEmToZRCSiVIMTkYjSWFQRibTMaKJqynIRSZq7J7SUxcyOM7N5ccsWM7vVzBqb2RQzWxL8bBQcb2Y2wsyWmtmnZta+vDiV4ESkAjzBpYwzuC9293bu3g44BdgBvAoMA6a5e2tgWrAN0AtoHSyDgSfLi1IJTkSS5LgXJrQkoTvwhbt/DVwIjA7KRwN9gvULgec8ZhbQ0MyalnVSJTgRqYCEa3BZZjY7bhlcygn7A0UvjMh299XB+hogO1jPAVbEfWZlUFYqdTKISAUk3Iua7+4dyjrAzA4BLgB+t99V3N3MKtxlqxqciCSlaLD9gXYyxOkFzHH3tcH22qKmZ/BzXVCeBzSP+1yzoKxUSnAikqREm6cJJ7gB7GmeAkwABgbrA4HxceVXBb2pnYDNcU3ZEqmJKiJJcy+olPOY2aFAD+C6uOL7gBfNbBDwNXBJUD4J6A0sJdbjenV551eCE5EKqJyRDO6+HWiyT9kGYr2q+x7rwJBkzq8EJyJJ0mwiIhJpSnAiEllKcCISUWqiikhEOVA5vaipdtAmuC8WL+bGSy8t3l6+bBm33XUXcz74gGWLFwOwZdMm6jdsyJvz5gHwxP/8D/8aNYrq1aszfMQIzjz33FBiD0u1atV4eeZM1q1ezfUXXwzArX/6Ez0vuoiCggLGPvMMz//tbyFHWXXqNGxIh8svp3a9euDOlx98wNKZM4v3t+7alRP79OH13/+eXdu3U7NOHU4ZMIDDsrIo+P57cseMYcuaNSH+BhWnGhxgZj2BR4HqwDPufl8qr5eMY447rjhxFRQU0DEnh3MvuohBt95afMzdv/419Rs0AODzhQt5fexYpixYwNpVq7j87LOZ8fnnVK9ePZT4w3DVL3/JssWLOax+fQD6XnEFR+bk0Kt9e9ydxllZIUdYtbywkM/Gj2fTypXUqFWLbr/+NWsXL2br2rXUadiQ7DZt2L5xY/HxbXr0YHNeHrOefZZ6RxxBu379eG/kyBB/gwORGQkuZSMZzKw68ASxYRhtgQFm1jZV1zsQ70+bRotjjqHZUUcVl7k7b7z4IhcMGADAlPHj+Wn//tSqVYsWrVrR8oc/ZN5HH4UVcpXL/sEPOPPcc3lp9Ojisv6DBjHy/vuL/zffmJ8fVnih+G7LFjatXAnA7p07Y4kt+A/xxD59+GzChL2Or5edzbolSwDYum4ddRs3ptZhh1Vt0JWmUkcypEwqh2qdBix192XuvgsYS2y6k7QzYezY4kRW5KP33iMrO5tWrVsDsCYvj6bN9wyDO7JZM9bklTkMLlLuuP9+HvjjH/HCPVPgtDj6aHr17cvL777LU+PGcdQxx4QYYbjqNm5Mw2bN2Pj11zQ9/ni+27yZzatW7XXM5lWryDnxRAAatWhB3UaNqNOwYRjhHpBEx6GmQzM2lQku6alNwrBr1y6mTpjAecE9pSITxozZL+kdrLr27MmG9etZEDTpi9Q85BB27dxJvzPP5KXRo7knY5tbB6b6IYfQ6eqr+eTVV/HCQtr06MGCN9/c77jFU6dSs04duv/mNxzzk5+wKS8vLZJAxWRGDS70ToZgfqjBAC1atKjy6894802Ob9+ew7Ozi8t2797N5FdeYWJubnHZkTk5rF6xJ1+vWbmSI3PSLl+nRPtOnejWuzdnnnMOh9SuzWH16vGXp59m7apVvB00w6ZMmMC9B2GCs2rV6PyLX7AiN5dVn35K/aZNqdu4MWcPHQpAnQYN6H777bzz0EPs3LqV3DF7xpT3/NOf2J6hzfrKGouaaqmswSU0tYm7P+XuHdy9w+GHH57CcEpWUk3t31OnckybNjRt1qy4rMcFF/D62LHs3LmT5V9+yZdLltDutNOqOtxQPDR8OF3btKH78cfz65//nA9nzmTotdcydeJEOnbpAsBpP/4xXy1dGnKkVe+UAQPYsnYtS2bMAGDL6tW88cc/Mvmuu5h81118u3kz0x54gJ1bt1KzTh0s6JRq2akT+V98we6dO0OMvqIqfTaRlEllDe5joLWZtSKW2PoDl6XweknbsX07702Zwr3/+797lb9ewj25Y3/0I8675BLObtuWGjVqcPcTTxxUPaglefqhh/jrqFH8fMgQdmzfzh9uvDHskKpUk1atOOrUU9m8ahXdf/MbABZMnMiaRYtKPL5edjYdLov9CWxZvZrcsWOrLNbKF37ySoSl8h6AmfUGHiH2mMiz7n5PWcd36NDBZ8+enbJ4Ml2bevXCDiHt3TNoUNghpLWhY8bwxdq1diDnOPnktj59+vMJHduoUYfc8mb0TaWU3oNz90nE5nASkUjJjBpc6J0MIpJpPNk3ZoVGCU5EKkAJTkQiqOilM5lACU5EkpQej4AkQglORCpACU5EIipTOhn0XlQRSZIT62RIZCmbmTU0s5fN7D9mtsjMOptZYzObYmZLgp+NgmPNzEaY2VIz+9TM2pd3fiU4EUmae2FCSwIeBSa7exvgJGARMAyY5u6tgWnBNsSmXmsdLIOBJ8s7uRKciFTAgY9FNbMGQBdgFIC773L3TcSmVSuaeHA00CdYvxB4zmNmAQ3NrGlZ11CCE5EKSDjBZZnZ7LhlcNxJWgHrgf8zs7lm9kzwpvtsd18dHLMGKJrqJ+kp2NTJICJJSmokQ34ZY1FrAO2Bm9z9QzN7lD3N0diV3N3MKtxlqxqciFRApUyXtBJY6e4fBtsvE0t4a4uansHPdcH+hKZgi6cEJyJJctwLElrKPIv7GmCFmR0XFHUHFgITgIFB2UBgfLA+Abgq6E3tBGyOa8qWSE1UEamASnvQ9ybgBTM7BFgGXE2s4vWimQ0CvgYuCY6dBPQGlgI7gmPLpAQnIkmpzLGo7j4PKOkeXfcSjnVgSDLnV4ITkeRlyGB73YMTkchSDU5EkuaFmVGDU4ITkSSlx0udE6EEJyLJyZzp4JTgRKQCVIMTkajKkPymBCciFZAhGU4JTkSSpk4GEYkmdTKISKSpBiciUeRkTH5TghORZHnGZDglOBFJWobkNyU4EUmSAxqLKiJR5RnSjZpWCe6z3FyOMgs7jLQ14Lzzwg4h7U2fPz/sENLa1m+/rZwTZUZ+S68EJyIZIkNuwinBiUjSMiS/KcGJSJJcE16KSGRlznNweieDiCSvUt77DGb2lZl9ZmbzzGx2UNbYzKaY2ZLgZ6Og3MxshJktNbNPzax9eedXghORpMSGanlCS4LOcvd27l70+sBhwDR3bw1MC7YBegGtg2Uw8GR5J1aCE5HkJFp7q3gr9kJgdLA+GugTV/6cx8wCGppZ07JOpAQnIklLogaXZWaz45bB+54KeNvMcuP2Zbv76mB9DZAdrOcAK+I+uzIoK5U6GUQkeYn3oubHNT1L8mN3zzOzI4ApZvaf+J3u7mZW4bqganAikjT3xJbyz+N5wc91wKvAacDaoqZn8HNdcHge0Dzu482CslIpwYlIcoomhDvADGdmh5pZvaJ14BxgPjABGBgcNhAYH6xPAK4KelM7AZvjmrIlUhNVRJJXOY/BZQOvWmz8eQ3gn+4+2cw+Bl40s0HA18AlwfGTgN7AUmAHcHV5F1CCE5EkVc6b7d19GXBSCeUbgO4llDswJJlrlJrgzOwxysjT7n5zMhcSkeiIwlCt2VUWhYhkjii8VcvdR8dvm1ldd9+R+pBEJO1FZSyqmXU2s4XAf4Ltk8xsZMojE5G0VEmdqFUikcdEHgHOBTYAuPsnQJdUBiUiaS5DMlxCvajuvsL2nkq8IDXhiEgmSIPclZBEEtwKMzsdcDOrCdwCLEptWCKSttwz5q1aiTRRryf27EkOsApoR5LPoohItFTydEkpU24Nzt3zgcurIBYRyRRpkLwSkUgv6tFm9rqZrTezdWY23syOrorgRCQ9ZUgfQ0JN1H8CLwJNgR8ALwFjUhmUiKSxDHpOJJEEV9fdn3f33cHyD6B2qgMTkTSW2hl9K01ZY1EbB6tvmtkwYCyxkC8lNqpfRA5SURiLmkssoRU9AHdd3D4HfpeqoEQkfXklzSZSFcoai9qqKgMRkQyRJs3PRCQ0ksHMjgfaEnfvzd2fS1VQIpLmMr0GV8TM7gS6Ektwk4i9m/DfgBKcyEEqU5qoifSi9iM2u+Yad7+a2AycDVIalYikNS/0hJawJdJE/dbdC81st5nVJ/aGm+blfSgTVatWjYmzZ7MmL49f/PSnNG/ZksfGjqVRkyZ8lpvLr668ku+//z7sMKtMv1tuoc2pp7Jt82YeGRIbndfjiito27Ej7s62TZt46ZFH2LpxI1369qVd164AVKtenSOaNePuyy/n223bQvwNUuvy22/n+I4d2bppE/deey0AJ3fpQu+rriK7RQseuPFGln/+OQDVa9RgwK230uK44ygsLGTcyJEs+eSTMMOvOAcKww4iMYnU4GabWUPgaWI9q3OAD8r7kJk9G4x8mH+AMVaZX9xyC0sX7ZlHYNj99zPq4Yc5s3VrNn/zDZcOGhRidFUvd+pUnr3zzr3KZo4bx6M33cSIm2/mPx9/TPcBA2Llr7zCiJtvZsTNN/PW6NF8OX9+pJMbwKy33uKJ3+39MMGqr77i6eHD+eKzz/YqP6N3bwDuvfZaHv/tb7nouuvYZ4aezBKVB33d/Zfuvsnd/wb0AAYGTdXy/B3oeYDxVZkjc3Lodt55jH3mmeKy07t1Y9LLLwMwbvRozunTJ6zwQvHlggV8u3XrXmU7v/22eP2Q2rVL/Ed8UpcuzJs5M+Xxhe2Lzz5jxz7fz9rly1m3cuV+xx551FEsnjcPgG2bNvHttm20OPbYKokzFSozv5lZdTOba2YTg+1WZvahmS01s3+Z2SFBea1ge2mwv2V55y41wZlZ+30XoDFQI1gv5wvwmcDGxH7F8N35yCPcO3QohYWxunejJk3YsmkTBQWxqe9Wr1zJkTk5YYaYNs658kqG/d//0a5rV6b84x977atZqxbHnnIK899/P6To0lPesmWc0Lkz1apVo8mRR9L82GNpdMQRYYdVQQlmt8RrcPtOwXY/8LC7/xD4BihqOg0CvgnKHw6OK1NZ9+AeLGOfA93KO3kizGwwMBigemWcsAK6nXceG9atY/6cOXQ688yQosgcbz//PG8//zxdL76Yzuefz9R//rN433+ddhpfL1oU+eZpsj54802yW7Rg6MiRbFy3ji8XLKCwIEPnja3E1qeZNQPOA+4BbrNYu70bcFlwyGhgOPAkcGGwDvAy8LiZmZfRpVvWg75nHWjwiXD3p4CnAGqZhdJo73DGGZx9wQV07d2bWrVrU69+fYY/+ij1GzakevXqFBQU0LRZM9bk5YURXtqaO2MGVw8fvleCO6lLF+a9+26IUaWnwsJCXnnyyeLt2x59tMSmbMYorLRehkeAoUC9YLsJsMnddwfbK4nNRUnwcwWAu+82s83B8fmlnTyRTobI+8sdd9CpeXN+3KoVN/Xvz/975x1uueIKPpg+nd79+gHws4EDmTJ+fMiRhq/JD35QvP6jjh1ZH/dHWqtuXVodfzwLZ80KI7S0VrNWrdg9S6BN+/YUFhSwZvnykKOqGAe8MLEFyDKz2XHL4KLzmNn5wDp3z01VrHqzfRn+57e/5fGxY7n9z39mwdy5/GvUqLBDqlL9f/Mbjj7hBA6tX5/f/f3vTHnhBdp06EBWs2Z4YSGb1q/n1SeeKD7++M6dWTJ3Lt/v3Bli1FXn53fcQeuTTuKwBg24e8wYJo0ezfatW7n4xhs5rEEDrr/nHvK++IInhg2jXsOGDLnvvtj3tmEDo++7L+zwK65ouqTE5Lt7h1L2nQFcYGa9iY2Sqg88CjQ0sxpBLa4ZUNR0yiP2iNpKM6tB7HncDWVd3FL1RLKZjSE2AiILWAvc6e5lZohaZn5kSqKJhgHnnRd2CGlv23ffhR1CWnvxo49Yt2XLAT2f0vboFv7CPbcndGz7y27JLSPBFTOzrsDt7n6+mb0EjHP3sWb2N+BTdx9pZkOAE9z9ejPrD/R190vKOm8iQ7WM2JTlR7v7XWbWAjjS3T8q63PuPqC8c4tIhkrtM26/Bcaa2Z+BuUBRxWgU8LyZLSX2hEb/8k6USBN1JLHnlrsBdwFbgXHAqcnHLSKZr/If4nX3GcCMYH0ZcFoJx3wHXJzMeRNJcB3dvb2ZzQ0u8k3Rg3cichBy8ILwRykkIpEE972ZVSeYAcrMDidjRqKJSCqkwSishCTymMgI4FXgCDO7h9hUSfemNCoRSW8ZMhY1kfeivmBmucSmTDKgj7vrzfYiByvPnPngEulFbQHsAF6PL3P3zHxKUUQOXIbcpErkHtwb7Hn5TG2gFbAY+FEK4xKRNBUbyRCRGpy7nxC/Hcwk8suURSQi6c0dopLg9uXuc8ysYyqCEZHMEKV7cLfFbVYD2gOrUhaRiKS/zMhvCdXg6sWt7yZ2T25casIRkYwQhRpc8IBvPXdPbGStiESfR6CToWi6EjM7oyoDEpH0l/EJDviI2P22eWY2AXgJ2F60091fSXFsIpKOMui1gYncg6tNbFK5bux5Hs4BJTiRg5JHohf1iKAHdT57EluRzPjtRCQ1ItBErQ4cxt6JrUhm/HYikhoZkgHKSnCr3f2uKotERDKCR2Sw/QHN2y4i0RWFCS+7V1kUIpI5nMy/B+fuG6syEBHJFNHoRRURKVmGPAenN9uLSNLcPaGlLGZW28w+MrNPzGyBmf13UN7KzD40s6Vm9q+il1yZWa1ge2mwv2V5cSrBiUhyHCjwxJay7QS6uftJQDugp5l1Au4HHnb3HwLfAIOC4wcB3wTlDwfHlUkJTkSSVhk1OI/ZFmzWDBYnNmrq5aB8NNAnWL8w2CbY3z14MX2plOBEJClOUgkuy8xmxy2D489lZtXNbB6wDpgCfAFscvfdwSErgZxgPQdYQez6u4HNQJOyYlUng4gkLYk+hnx371DaTncvANqZWUNirydtc8DBxVENTkSSk2DtLZlHSdx9EzAd6Aw0NLOiylczIC9YzwOaQ2w6N6ABsYlASqUEJyJJq6Re1MODmhtmVgfoASwiluj6BYcNBMYH6xOCbYL973g5F1ETVUSSEhvIUCkP+jYFRgczh1cDXnT3iWa2EBhrZn8G5gKjguNHAc+b2VJgI9C/vAukVYJrWL8+fTt3DjuMtDVn2bKwQ0h7E+e9H3YIae2Dzt0q5TyVMZLB3T8FTi6hfBlwWgnl3wEXJ3ONtEpwIpIZNFRLRCIrM9KbEpyIJCnZHtIwKcGJSNIqqZMh5ZTgRCRpqsGJSGQpwYlIJBWNRc0ESnAikrQMme9SCU5EkqReVBGJKgcKCzOjDqcEJyJJy4z6mxKciFSAmqgiEllKcCISSe6ukQwiEl2Zkd6U4ESkAtSLKiKRpXtwIhJJlThlecopwYlIcjSSQUSiLDPSmxKciCTJgYIM6WTQe1FFJGmV9F7U5mY23cwWmtkCM7slKG9sZlPMbEnws1FQbmY2wsyWmtmnZta+vDiV4EQkaZX0ZvvdwK/dvS3QCRhiZm2BYcA0d28NTAu2AXoBrYNlMPBkeRdQghORpCSa3MpLcO6+2t3nBOtbib3VPge4EBgdHDYa6BOsXwg85zGzgIZm1rSsa+genIgkLYk7cFlmNjtu+yl3f2rfg8ysJbGXQH8IZLv76mDXGiA7WM8BVsR9bGVQtppSKMGJSNKSeEwk3907lHWAmR0GjANudfctZhZ/HTezCnfaKsGJSFIqsxfVzGoSS24vuPsrQfFaM2vq7quDJui6oDwPaB738WZBWal0D05EklZJvagGjAIWuftDcbsmAAOD9YHA+Ljyq4Le1E7A5rimbIlUgxOR5FTeSIYzgCuBz8xsXlB2B3Af8KKZDQK+Bi4J9k0CegNLgR3A1eVdQAlORJJSWWNR3f3fgJWyu3sJxzswJJlrKMGJSNI0FjXN9f/Vr2jbsSPbNm3iL9dfD8BPr7mGH3XsSMHu3eSvWsWYhx7iu+3baX/WWXTr16/4s01bteLBG29k1bJlYYVf5Zq1bMnvH9pzm+TIZs147rHHmDphAr9/8EGyc3JYm5fHn2+7jW1btoQYadVZtngJt1wxqHh7xZdfccuffsfaVauZ/sZb1DykJi2ObsV9Tz9O/YYNio9btXwlvdp15qY/DOWa224KI/QDlikJLmWdDKUNw0gXH02ZwlN/+MNeZZ/PmcNfrruOv95wA+vz8jj70ksBmDN9Og8MGcIDQ4bwwl//ysY1aw6q5Aaw8quvuKFvX27o25ch/fqx87vveH/aNC695hrmzprF1b16MXfWLC695pqwQ60yRx/Xmtc/nsnrH8/ktVnTqVO3LudceD5ndO/KG3PfZ2Luv2nZ+hj+9peH9/rcvUN/T5dz92uBZQx3p6CwMKElbKnsRS1tGEZaWDZ/Ptu3bt2rbPGcOcUzlX79n//QMCtrv8+d3LUrc999t0piTFcnd+rE6uXLWbdqFZ27dWPKa68BMOW11zi9e+b+4R6I//fOu7Q4uiU5RzXnJz26UaNGrHHUrmMH1uStKj5uyvg3aNbyKFq3bRNWqJWiMHgvQ3lL2FKW4MoYhpEROp5zDotmz96v/OQuXZgzY0bVB5RGzuzdm+mTJgHQqEkTNubnA7AxP59GTZqEGVpo3njpFc6/5Gf7lb/89xc489yzAdi+bRtPPfgoN/1haFWHV+kqaSxqylXJc3D7DMNIe2f3709BQQG577yzV3mL445j186drPn665AiC1+NmjXpfNZZzHzrrRL3p8M/6qq2a9cu3pk4mV4/u3Cv8pH3PUiNGjW4YMDFADx29/1cffMNHHrYYWGEWWmKelEzoQaX8k6GfYdhlLB/MLGZAahXu3aqwynXqT168KOOHRk5bNh++9qfeSZzD/La26k/+QlLFy5k04YNAHyzYQONs7LYmJ9P46wsNm3cGHKEVW/m5Km0bXciWdlHFJeNe+6fTJ/0Fs9Nfo2ioUeffJzL5Fcn8Jc7hrNl02aqVatGrdq1ufKX14YVeoVlyn9kKU1wpQzD2Esw8PYpgOwGDUL91tqccgrd+vXj8aFD+X7nzr32mRkndenC47ffHlJ06eGsuOYpwKzp0+nRpw//euYZevTpwwf71HoPBhNfHMf5l+5pns58aypPPziCF6ZOpE7dusXlY97Z872NuPs+6h56aEYmN4JOhkyQsgRXxjCMtHDlsGH88MQTObR+fe58/nkm/+MfdL/0UmrUrMkN994LxDoaXnrsMQCOPuEENq1fz4Y1a8IMO1S169Sh/emn88jw4cVlY59+mj88/DA9f/Yz1q5axT233RZegCHYsX0770+bwd1P7Okp/e9bf8uuXTv5ee++ALQ7rQN3P5F2fwIVlkkvnbFUVTXN7MfAe8Bn7Jld5Q53n1TaZ7IbNPDLOndOSTxRsGD58rBDSHsT570fdghprXPnbuTmzi1t9EBCftCokV/btWtCx9712mu55c0mkkopq8GVMwxDRDJVmnQgJOKgHckgIhXjqJNBRCJMNTgRiaRMem2gEpyIJEf34EQkypTgRCSSHHA1UUUkqlSDE5Fo0j04EYkqB3YXFIQdRkKU4EQkaZnyoK/eiyoiSfEE54JLpBlrZs+a2Tozmx9X1tjMppjZkuBno6DczGyEmS01s0/NrH1551eCE5GkFRYWJrQk4O9Az33KhgHT3L01MC3YBugFtA6WwcCT5Z1cCU5EklKZM/q6+0xg31lSLwRGB+ujgT5x5c95zCygoZk1Lev8ugcnIslxT6aTIcvM4l9u8lQwyW1Zst19dbC+BsgO1nOAFXHHrQzKVlMKJTgRSYoDBYl3MuQfyHxw7u5mVuEeDSU4EUlagvfXKmqtmTV199VBE3RdUJ4HNI87rllQVirdgxORpFRmL2opJgADg/WBwPi48quC3tROwOa4pmyJVIMTkaRVVg3OzMYAXYndq1sJ3AncB7xoZoOAr4FLgsMnAb2BpcAO4Oryzq8EJyJJqcz54Nx9QCm7updwrANDkjm/EpyIJMXd+V5DtUQkqlLcyVBplOBEJCmuFz+LSFTpnQwiEl2qwYlIVDm6ByciEeXu7Ny1K+wwEqIEJyJJcXd2qwYnIlFVoOfgRCSKvLCQ73fuDDuMhCjBiUhS3J3vdQ9ORKKosLCQHVu3hh1GQiyd3o5jZuuJzR6QLrKA/LCDSGP6fsqXbt/RUe5++IGcwMwmE/u9EpHv7vu+c6HKpFWCSzdmNvtAZiONOn0/5dN3FC5NeCkikaUEJyKRpQRXtvLe/nOw0/dTPn1HIdI9OBGJLNXgRCSylOBEJLKU4EpgZj3NbLGZLTWzYWHHk27M7FkzW2dm88OOJR2ZWXMzm25mC81sgZndEnZMByvdg9uHmVUHPgd6ACuBj4EB7r4w1MDSiJl1AbYBz7n78WHHk26ClxU3dfc5ZlYPyAX66N9Q1VMNbn+nAUvdfZm77wLGAheGHFNacfeZwMaw40hX7r7a3ecE61uBRUBOuFEdnJTg9pcDrIjbXon+cUoFmVlL4GTgw3AjOXRMX2YAAAO1SURBVDgpwYmkiJkdBowDbnX3LWHHczBSgttfHtA8brtZUCaSMDOrSSy5veDur4Qdz8FKCW5/HwOtzayVmR0C9AcmhByTZBAzM2AUsMjdHwo7noOZEtw+3H03cCPwFrGbwy+6+4Jwo0ovZjYG+AA4zsxWmtmgsGNKM2cAVwLdzGxesPQOO6iDkR4TEZHIUg1ORCJLCU5EIksJTkQiSwlORCJLCU5EIksJLoOYWUHwyMF8M3vJzOoewLn+bmb9gvVnzKxtGcd2NbPTK3CNr8xsv7cvlVa+zzHbkrzWcDO7PdkYJdqU4DLLt+7eLpjBYxdwffxOM6vQe27d/ZpyZrroCiSd4ETCpgSXud4DfhjUrt4zswnAQjOrbmZ/NbOPzexTM7sOYk/Xm9njwTx3U4Ejik5kZjPMrEOw3tPM5pjZJ2Y2LRgsfj3wq6D2+BMzO9zMxgXX+NjMzgg+28TM3g7mQHsGsPJ+CTN7zcxyg88M3mffw0H5NDM7PCg7xswmB595z8zaVMaXKdGkN9tnoKCm1guYHBS1B4539y+DJLHZ3U81s1rA+2b2NrEZLY4D2gLZwELg2X3OezjwNNAlOFdjd99oZn8Dtrn7A8Fx/wQedvd/m1kLYqM+/gu4E/i3u99lZucBiYxw+EVwjTrAx2Y2zt03AIcCs939V2b2p+DcNxJ7icv17r7EzDoCI4FuFfga5SCgBJdZ6pjZvGD9PWLjHU8HPnL3L4Pyc4ATi+6vAQ2A1kAXYIy7FwCrzOydEs7fCZhZdC53L23Ot7OBtrEhlwDUD2bO6AL0DT77hpl9k8DvdLOZXRSsNw9i3QAUAv8Kyv8BvBJc43Tgpbhr10rgGnKQUoLLLN+6e7v4guAPfXt8EXCTu7+1z3GVORayGtDJ3b8rIZaEmVlXYsmys7vvMLMZQO1SDvfgupv2/Q5ESqN7cNHzFnBDMF0PZnasmR0KzAQuDe7RNQXOKuGzs4AuZtYq+GzjoHwrUC/uuLeBm4o2zKwo4cwELgvKegGNyom1AfBNkNzaEKtBFqkGFNVCLyPW9N0CfGlmFwfXMDM7qZxryEFMCS56niF2f22OxV4K87/EauqvAkuCfc8Rmw1kL+6+HhhMrDn4CXuaiK8DFxV1MgA3Ax2CToyF7OnN/W9iCXIBsabq8nJinQzUMLNFwH3EEmyR7cBpwe/QDbgrKL8cGBTEtwBNJy9l0GwiIhJZqsGJSGQpwYlIZCnBiUhkKcGJSGQpwYlIZCnBiUhkKcGJSGT9f7bIqT2cfRGpAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(Y_test, y_pred, cmap=plt.cm.pink)  \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdKeffHHKFkJ"
      },
      "source": [
        "## Learning Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "uc-F-ub8FXKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "2603bc8b-9167-4c82-8a30-04ae457fd60b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7625582237243652, 0.6472433953285217, 0.5724480683803559]\n",
            "[0.6862345933914185, 0.6652163863182068, 0.6738044023513794]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# plot\n",
        "print(epoch_loss)\n",
        "print(validation_loss)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.arange(epochs), validation_loss, color=\"pink\", lw=2, label='validation')\n",
        "ax.plot(np.arange(epochs), epoch_loss, color=\"b\", lw=2, label='training')\n",
        "\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Cross Entropy Loss')\n",
        "\n",
        "ax.grid()\n",
        "ax.legend(loc=0)\n",
        "plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "ecDEwd5B_Rk_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "d4383bb4-58a1-4cd8-e3ac-1657fa7ca539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: scipy.interp is deprecated and will be removed in SciPy 2.0.0, use numpy.interp instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# CODE FROM https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "\n",
        "if device==torch.device(\"cuda\"):\n",
        "  y_score = scores.detach().cpu().numpy()\n",
        "else:\n",
        "  y_score = scores.detach().numpy()\n",
        "\n",
        "y_test = np.array(pd.get_dummies(Y_test))\n",
        "n_classes = 3\n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "################################################################################\n",
        "\n",
        "# First aggregate all false positive rates\n",
        "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "# Then interpolate all ROC curves at this points\n",
        "mean_tpr = np.zeros_like(all_fpr)\n",
        "for i in range(n_classes):\n",
        "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "# Finally average it and compute AUC\n",
        "mean_tpr /= n_classes\n",
        "\n",
        "fpr[\"macro\"] = all_fpr\n",
        "tpr[\"macro\"] = mean_tpr\n",
        "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "# Plot all ROC curves\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.plot(\n",
        "    fpr[\"micro\"],\n",
        "    tpr[\"micro\"],\n",
        "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
        "    color=\"deeppink\",\n",
        "    linestyle=\":\",\n",
        "    linewidth=4,\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    fpr[\"macro\"],\n",
        "    tpr[\"macro\"],\n",
        "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
        "    color=\"navy\",\n",
        "    linestyle=\":\",\n",
        "    linewidth=4,\n",
        ")\n",
        "\n",
        "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
        "for i, color in zip(range(n_classes), colors):\n",
        "    plt.plot(\n",
        "        fpr[i],\n",
        "        tpr[i],\n",
        "        color=color,\n",
        "        lw=3,\n",
        "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
        "    )\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=3)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic length of sequences\n",
        "\n",
        "Using bucket iterator for dataloader and an embedding layer in our models."
      ],
      "metadata": {
        "id": "Qz1QIYvfu4cE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, I am going to redefine the models to add the embedding layer and to make it compatible with the batches for BucketIteratot."
      ],
      "metadata": {
        "id": "bS29vr0zdCDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bidirectional LSTM\n",
        "class BRNN2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, cell, embedding, dropout=0.3, attention=True):\n",
        "        super(BRNN2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell = cell\n",
        "        self.bidirectional = True\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding))\n",
        "        self.attention = attention\n",
        "        self.scale = 1. / math.sqrt(hidden_size)\n",
        "        if (cell == 'LSTM'):\n",
        "          self.rnn = nn.LSTM(\n",
        "              input_size, hidden_size, num_layers, bidirectional=True, dropout=dropout\n",
        "          )\n",
        "        else:\n",
        "          self.rnn = nn.GRU(\n",
        "              input_size, hidden_size, num_layers, bidirectional=True, dropout=dropout\n",
        "          )\n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        if (self.cell == 'LSTM'):\n",
        "          out, hidden = self.rnn(x)\n",
        "          hidden = hidden[1]\n",
        "        else:\n",
        "          out, hidden = self.rnn(x)\n",
        "\n",
        "        if (self.attention==True):\n",
        "\n",
        "            if (self.bidirectional==True):\n",
        "                hidden = torch.cat([hidden[-1], hidden[-2]], dim=1) # concatinate the last 2 hidden cells (backward & forward)\n",
        "            else:\n",
        "                hidden = hidden[-1]\n",
        "\n",
        "            query = hidden.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
        "            values = out\n",
        "            keys = out.transpose(0,1).transpose(1,2) # [BxTxK] -> [BxKxT]\n",
        "      \n",
        "            attention_scores = torch.bmm(query, out.transpose(0,1).transpose(1,2)) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
        "            attention_distribution = F.softmax(attention_scores.mul_(self.scale), dim=2) # scale, normalize\n",
        "\n",
        "            out = torch.bmm(attention_distribution, out.transpose(0,1)).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
        "\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "\n",
        "            out = self.fc(out[-1, :, :])\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "xZ7R-9TmGOCJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same for skip connections."
      ],
      "metadata": {
        "id": "1HNjuAs_dj2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class skipBRNN2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes, cell, embedding, attention=True):\n",
        "        super(skipBRNN2, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell = cell\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding))\n",
        "        self.attention = attention\n",
        "        self.bidirectional = True\n",
        "        self.scale = 1. / math.sqrt(hidden_size)\n",
        "        \n",
        "        if (cell == 'LSTM'):\n",
        "            rnn = nn.LSTM\n",
        "        else:\n",
        "            rnn = nn.GRU\n",
        "\n",
        "        self.rnns = nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            input_size = input_size if i == 0 else hidden_size*2\n",
        "            self.rnns.append(rnn(input_size, hidden_size, 1, bidirectional=True))\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        sent_variable = self.embedding(x)\n",
        "        # print(\"after embedding\", sent_variable.shape)\n",
        "\n",
        "        # outputs = []\n",
        "        for i in range(self.num_layers):\n",
        "            if i != 0:\n",
        "                sent_variable = self.dropout(sent_variable.detach())\n",
        "            # print(i)\n",
        "            # print(\"rnn input:\" ,sent_variable.shape)\n",
        "            out, hidden = self.rnns[i](sent_variable.detach())\n",
        "            hidden = hidden[1]\n",
        "            # print(\"rnn output:\", out.shape)\n",
        "            # outputs.append(out)\n",
        "            # sent_variable = out\n",
        "            if i == 0:\n",
        "                sent_variable = out.detach()\n",
        "            sent_variable = torch.cat((sent_variable,out.detach()),dim=0)\n",
        "\n",
        "        if (self.attention==True):\n",
        "\n",
        "            if (self.bidirectional==True):\n",
        "                hidden = torch.cat([hidden[-1], hidden[-2]], dim=1) # concatinate the last 2 hidden cells (backward & forward)\n",
        "            else:\n",
        "                hidden = hidden[-1]\n",
        "\n",
        "            # print(\"hidden\", hidden.shape)\n",
        "            query = hidden.unsqueeze(1) # [BxQ] -> [Bx1xQ]\n",
        "            values = out\n",
        "            # print(\"query\", query.shape)\n",
        "            # print(\"keys\", out.shape)\n",
        "            keys = out.transpose(0,1).transpose(1,2) # [BxTxK] -> [BxKxT]\n",
        "            # print(\"keys\", keys.shape)\n",
        "            attention_scores = torch.bmm(query, out.transpose(0,1).transpose(1,2)) # [Bx1xQ]x[BxKxT] -> [Bx1xT]\n",
        "            attention_distribution = F.softmax(attention_scores.mul_(self.scale), dim=2) # scale, normalize\n",
        "\n",
        "            # out = out # [TxBxV] -> [BxTxV]\n",
        "            # print(\"values\", values.shape)\n",
        "            out = torch.bmm(attention_distribution, out.transpose(0,1)).squeeze(1) #[Bx1xT]x[BxTxV] -> [BxV]\n",
        "            # print(\"out\", out.shape)\n",
        "            out = self.fc(out)\n",
        "        else:\n",
        "            # print(\"out\", out[-1, :, :].shape)\n",
        "            out = self.fc(out[-1, :, :])\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "pzJ4shSuo8z5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[link text](https://www.slideshare.net/fgodin/skip-residual-and-densely-connected-rnn-architectures)"
      ],
      "metadata": {
        "id": "2Gtogu00QYVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the vectors."
      ],
      "metadata": {
        "id": "djpztiHuE3ND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "4KYbNJ2Sze59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f8ff04-0538-479c-913a-f3fe5691a0aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1193514 [00:00<?, ?it/s]Skipping token b'1193514' with 1-dimensional vector [b'200']; likely a header\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1193514/1193514 [02:30<00:00, 7942.86it/s]\n"
          ]
        }
      ],
      "source": [
        "glove_vocab  = vocab.Vectors(r\"/content/drive/MyDrive/Colab Notebooks/Artificial Intelligence II/glove.twitter.27B.200d.txt.gz (Unzipped Files)/glove.twitter.27B.200d.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new datasets with only the useful columns."
      ],
      "metadata": {
        "id": "7WX54-fDE8Ky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_new = df_train.drop(columns=['tweet', 'features'])"
      ],
      "metadata": {
        "id": "kviQ0DeB4lZ_"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_new = df_test.drop(columns=['tweet', 'features'])"
      ],
      "metadata": {
        "id": "fEMf_Od14zf4"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://gmihaila.medium.com/better-batches-with-pytorchtext-bucketiterator-12804a545e2a"
      ],
      "metadata": {
        "id": "DejbauPJT-1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the dataloaders for batches."
      ],
      "metadata": {
        "id": "xFiFHNioFFTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.setstate(random.getstate())\n",
        "text_field = Field(tokenize=nltk.word_tokenize,lower=True,sequential=True, fix_length=31) # tokenize text using word_tokenize and convert to numerical form using default parameters\n",
        "label_field = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "fields = [('label',label_field),('clean_tweet',text_field)]\n",
        "\n",
        "preprocessed_text = df_train_new['clean_tweet'].apply(lambda x: text_field.preprocess(x))\n",
        "text_field.build_vocab(preprocessed_text,vectors=glove_vocab)\n",
        "\n",
        "train_dataset = Dataset(\n",
        "    examples=[Example.fromlist(list(r),fields) for i,r in df_train_new.iterrows()],\n",
        "    fields=fields)\n",
        "\n",
        "preprocessed_text_test = df_test_new['clean_tweet'].apply(lambda x: text_field.preprocess(x))\n",
        "text_field.build_vocab(preprocessed_text_test,vectors=glove_vocab)\n",
        "\n",
        "test_dataset = Dataset(\n",
        "    examples=[Example.fromlist(list(r),fields) for i,r in df_test_new.iterrows()],\n",
        "    fields=fields)\n",
        "\n"
      ],
      "metadata": {
        "id": "rruSfBwzOo4E"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "TR_hF6_U6T2W"
      },
      "outputs": [],
      "source": [
        "def train2(model, learning_rate, train_dataset, test_dataset, batch_size, epochs, device):\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    epoch_loss = []\n",
        "    validation_loss = []\n",
        "\n",
        "    train_loader, test_loader = BucketIterator.splits(\n",
        "        datasets=(train_dataset, test_dataset),         # Datasets for iterator to draw data from\n",
        "        batch_sizes=(batch_size, batch_size),           # Tuple of train and validation batch sizes.\n",
        "        sort=False,                                     # Sort all examples in data using `sort_key`.\n",
        "        device=device,                                  # Device to load batches on.\n",
        "        sort_key=lambda x: len(x.clean_tweet),     # Function to use for sorting examples.\n",
        "        shuffle=True,                                   # Shuffle data on each epoch run.\n",
        "        sort_within_batch=True                          # Use `sort_key` to sort examples in each batch.\n",
        "    )\n",
        "    # Train Network\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        batch_losses = []\n",
        "        for batch in train_loader:\n",
        "\n",
        "            data = batch.clean_tweet\n",
        "            targets = batch.label\n",
        "\n",
        "            data = data.to(device=device).squeeze(1) # to device\n",
        "            targets = targets.to(device=device) # to device\n",
        "\n",
        "            # forward\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "            # backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip params\n",
        "            for param in model.parameters():\n",
        "                if param.grad is None:\n",
        "                    continue\n",
        "                grad_val = torch.clamp(param.grad, -5, 5)\n",
        "\n",
        "            # adam step\n",
        "            optimizer.step()\n",
        "            \n",
        "        epoch_loss.append(sum(batch_losses)/len(train_loader))\n",
        "        \n",
        "        model.eval()\n",
        "        batch_val_losses = []\n",
        "        with torch.no_grad():\n",
        "            for test_batch in test_loader:\n",
        "                x = test_batch.clean_tweet\n",
        "                y = test_batch.label\n",
        "                x = x.to(device=device).squeeze(1)\n",
        "                y = y.to(device=device)\n",
        "\n",
        "                scores = model(x)\n",
        "                loss = criterion(scores, y)\n",
        "\n",
        "                batch_val_losses.append(loss.item())\n",
        "\n",
        "            validation_loss.append(sum(batch_val_losses)/len(test_loader))\n",
        "\n",
        "        print(f\"Epoch {epoch:3}: Training Loss = {sum(batch_losses)/len(train_loader):.5f} Validation Loss = {validation_loss[epoch]:.5f}\")\n",
        "        # if (val_loss>validation_loss[epoch-1]+0.3): #early stopping\n",
        "        n_epochs = epoch+1\n",
        "        #     break \n",
        "\n",
        "    model.eval()\n",
        "    total_scores = torch.empty((0,3)).to(device=device)\n",
        "    labels = torch.empty((0)).to(device=device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_batch in test_loader:\n",
        "            x = test_batch.clean_tweet.to(device=device).squeeze(1)\n",
        "            y = test_batch.label.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "\n",
        "            total_scores = torch.concat((total_scores, scores), 0)\n",
        "            labels = torch.concat((labels, y), 0)\n",
        "                    \n",
        "    _, y_pred = total_scores.max(1)\n",
        "\n",
        "    if device==torch.device(\"cuda\"):\n",
        "        y_pred =  y_pred.cpu()\n",
        "        labels = labels.cpu()\n",
        "\n",
        "    print(\"\")\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(labels, y_pred)\n",
        "    print(f\"         precision\\t  recall\\t   f1\\t    \\tsupport\")\n",
        "    print(f\"--------------------------------------------------------------\")\n",
        "    print(f\"label 0 | {precision[0]*100:0.4f}\\t {recall[0]*100:0.4f}\\t {f1[0]*100:0.4f}\\t {support[0]}\")\n",
        "    print(f\"label 1 | {precision[1]*100:0.4f}\\t {recall[1]*100:0.4f}\\t {f1[1]*100:0.4f}\\t {support[1]}\")\n",
        "    print(f\"label 2 | {precision[2]*100:0.4f}\\t {recall[2]*100:0.4f}\\t {f1[2]*100:0.4f}\\t {support[2]}\")\n",
        "\n",
        "    average = precision_recall_fscore_support(labels, y_pred, average='micro')\n",
        "    print(f\"micro   | {average[0]*100:0.4f}\\t {average[1]*100:0.4f}\\t {average[2]*100:0.4f}\\t -\")\n",
        "\n",
        "    return epoch_loss, validation_loss, y_pred, scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimentation"
      ],
      "metadata": {
        "id": "srjH_Qk82Pwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed()\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 200\n",
        "num_layers = 2\n",
        "hidden_size = 128\n",
        "num_classes = 3\n",
        "learning_rate = 0.01\n",
        "batch_size = 64\n",
        "cell = 'LSTM'\n",
        "epochs = 3\n",
        "\n",
        "# Initialize network\n",
        "embedding = text_field.vocab.vectors\n",
        "model = BRNN2(input_size, hidden_size, num_layers, num_classes, cell, embedding=embedding).to(device)\n",
        "epoch_loss, validation_loss, y_pred, scores = train2(model, learning_rate, train_dataset, test_dataset, batch_size, epochs, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY-qqtW2u9S2",
        "outputId": "0370881e-5fd6-4d7d-a0e9-3dfdaf4e4c54"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   0: Training Loss = 0.78514 Validation Loss = 0.69819\n",
            "Epoch   1: Training Loss = 0.66414 Validation Loss = 0.67816\n",
            "Epoch   2: Training Loss = 0.61838 Validation Loss = 0.66678\n",
            "\n",
            "         precision\t  recall\t   f1\t    \tsupport\n",
            "--------------------------------------------------------------\n",
            "label 0 | 80.6163\t 76.1502\t 78.3197\t 1065\n",
            "label 1 | 61.7143\t 36.4865\t 45.8599\t 296\n",
            "label 2 | 65.1226\t 77.8502\t 70.9199\t 921\n",
            "micro   | 71.6915\t 71.6915\t 71.6915\t -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Curves"
      ],
      "metadata": {
        "id": "55ptIiC9bGY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "n_epochs = epochs\n",
        "print(epoch_loss)\n",
        "print(validation_loss)\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.arange(n_epochs), validation_loss, color=\"pink\", lw=2, label='validation')\n",
        "ax.plot(np.arange(n_epochs), epoch_loss, color=\"b\", lw=2, label='training')\n",
        "\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Cross Entropy Loss')\n",
        "\n",
        "ax.grid()\n",
        "ax.legend(loc=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "Rr2Uzc48fBHD",
        "outputId": "ed233644-17f4-4020-ebc1-ca31bdbf5786"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7851437726020813, 0.6641406098604202, 0.6183834091424942]\n",
            "[0.6981934772597419, 0.6781644307904773, 0.6667788525422415]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AI2-HM3 bidirectional RNN with LSTM/GRU.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2pdsWAP9TCbKm+lEMokwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}